{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "dc9f9c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "from warnings import simplefilter\n",
    "simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# data science\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# visualization imports\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score, roc_curve\n",
    "\n",
    "# Algorithms\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "# fun ones\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier\n",
    "\n",
    "seed = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "e7d70d2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>disposition</th>\n",
       "      <th>victim_sex</th>\n",
       "      <th>victim_race</th>\n",
       "      <th>victim_age</th>\n",
       "      <th>age_range</th>\n",
       "      <th>reported_date</th>\n",
       "      <th>reported_year</th>\n",
       "      <th>reported_month</th>\n",
       "      <th>reported_weekday</th>\n",
       "      <th>season</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>LOCATION</th>\n",
       "      <th>POPULATION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alb-000001</td>\n",
       "      <td>No Arrest</td>\n",
       "      <td>Male</td>\n",
       "      <td>Hispanic</td>\n",
       "      <td>78</td>\n",
       "      <td>65+</td>\n",
       "      <td>2010-05-04</td>\n",
       "      <td>2010</td>\n",
       "      <td>May</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>Spring</td>\n",
       "      <td>Albuquerque</td>\n",
       "      <td>NM</td>\n",
       "      <td>35.095788</td>\n",
       "      <td>-106.538555</td>\n",
       "      <td>Albuquerque, NM</td>\n",
       "      <td>545852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alb-000002</td>\n",
       "      <td>Arrest Made</td>\n",
       "      <td>Male</td>\n",
       "      <td>Hispanic</td>\n",
       "      <td>17</td>\n",
       "      <td>0-17</td>\n",
       "      <td>2010-02-16</td>\n",
       "      <td>2010</td>\n",
       "      <td>February</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>Winter</td>\n",
       "      <td>Albuquerque</td>\n",
       "      <td>NM</td>\n",
       "      <td>35.056810</td>\n",
       "      <td>-106.715321</td>\n",
       "      <td>Albuquerque, NM</td>\n",
       "      <td>545852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alb-000003</td>\n",
       "      <td>No Arrest</td>\n",
       "      <td>Female</td>\n",
       "      <td>White</td>\n",
       "      <td>15</td>\n",
       "      <td>0-17</td>\n",
       "      <td>2010-06-01</td>\n",
       "      <td>2010</td>\n",
       "      <td>June</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Albuquerque</td>\n",
       "      <td>NM</td>\n",
       "      <td>35.086092</td>\n",
       "      <td>-106.695568</td>\n",
       "      <td>Albuquerque, NM</td>\n",
       "      <td>545852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alb-000004</td>\n",
       "      <td>Arrest Made</td>\n",
       "      <td>Male</td>\n",
       "      <td>Hispanic</td>\n",
       "      <td>32</td>\n",
       "      <td>30-44</td>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>2010</td>\n",
       "      <td>January</td>\n",
       "      <td>Friday</td>\n",
       "      <td>Winter</td>\n",
       "      <td>Albuquerque</td>\n",
       "      <td>NM</td>\n",
       "      <td>35.078493</td>\n",
       "      <td>-106.556094</td>\n",
       "      <td>Albuquerque, NM</td>\n",
       "      <td>545852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alb-000005</td>\n",
       "      <td>No Arrest</td>\n",
       "      <td>Female</td>\n",
       "      <td>White</td>\n",
       "      <td>72</td>\n",
       "      <td>65+</td>\n",
       "      <td>2010-01-02</td>\n",
       "      <td>2010</td>\n",
       "      <td>January</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>Winter</td>\n",
       "      <td>Albuquerque</td>\n",
       "      <td>NM</td>\n",
       "      <td>35.130357</td>\n",
       "      <td>-106.580986</td>\n",
       "      <td>Albuquerque, NM</td>\n",
       "      <td>545852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47473</th>\n",
       "      <td>Was-001380</td>\n",
       "      <td>Arrest Made</td>\n",
       "      <td>Male</td>\n",
       "      <td>Black</td>\n",
       "      <td>29</td>\n",
       "      <td>18-29</td>\n",
       "      <td>2016-09-08</td>\n",
       "      <td>2016</td>\n",
       "      <td>September</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>Fall</td>\n",
       "      <td>Washington</td>\n",
       "      <td>DC</td>\n",
       "      <td>38.828704</td>\n",
       "      <td>-77.002075</td>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>687576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47474</th>\n",
       "      <td>Was-001381</td>\n",
       "      <td>No Arrest</td>\n",
       "      <td>Male</td>\n",
       "      <td>Black</td>\n",
       "      <td>19</td>\n",
       "      <td>18-29</td>\n",
       "      <td>2016-09-13</td>\n",
       "      <td>2016</td>\n",
       "      <td>September</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>Fall</td>\n",
       "      <td>Washington</td>\n",
       "      <td>DC</td>\n",
       "      <td>38.822852</td>\n",
       "      <td>-77.001725</td>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>687576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47475</th>\n",
       "      <td>Was-001382</td>\n",
       "      <td>No Arrest</td>\n",
       "      <td>Male</td>\n",
       "      <td>Black</td>\n",
       "      <td>23</td>\n",
       "      <td>18-29</td>\n",
       "      <td>2016-11-14</td>\n",
       "      <td>2016</td>\n",
       "      <td>November</td>\n",
       "      <td>Monday</td>\n",
       "      <td>Fall</td>\n",
       "      <td>Washington</td>\n",
       "      <td>DC</td>\n",
       "      <td>38.828025</td>\n",
       "      <td>-77.002511</td>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>687576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47476</th>\n",
       "      <td>Was-001383</td>\n",
       "      <td>No Arrest</td>\n",
       "      <td>Male</td>\n",
       "      <td>Black</td>\n",
       "      <td>24</td>\n",
       "      <td>18-29</td>\n",
       "      <td>2016-11-30</td>\n",
       "      <td>2016</td>\n",
       "      <td>November</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>Fall</td>\n",
       "      <td>Washington</td>\n",
       "      <td>DC</td>\n",
       "      <td>38.820476</td>\n",
       "      <td>-77.008640</td>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>687576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47477</th>\n",
       "      <td>Was-001384</td>\n",
       "      <td>Arrest Made</td>\n",
       "      <td>Male</td>\n",
       "      <td>Black</td>\n",
       "      <td>17</td>\n",
       "      <td>0-17</td>\n",
       "      <td>2016-09-01</td>\n",
       "      <td>2016</td>\n",
       "      <td>September</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>Fall</td>\n",
       "      <td>Washington</td>\n",
       "      <td>DC</td>\n",
       "      <td>38.866689</td>\n",
       "      <td>-76.982409</td>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>687576</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>47478 rows Ã 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              uid  disposition victim_sex victim_race  victim_age age_range  \\\n",
       "0      Alb-000001    No Arrest       Male    Hispanic          78       65+   \n",
       "1      Alb-000002  Arrest Made       Male    Hispanic          17      0-17   \n",
       "2      Alb-000003    No Arrest     Female       White          15      0-17   \n",
       "3      Alb-000004  Arrest Made       Male    Hispanic          32     30-44   \n",
       "4      Alb-000005    No Arrest     Female       White          72       65+   \n",
       "...           ...          ...        ...         ...         ...       ...   \n",
       "47473  Was-001380  Arrest Made       Male       Black          29     18-29   \n",
       "47474  Was-001381    No Arrest       Male       Black          19     18-29   \n",
       "47475  Was-001382    No Arrest       Male       Black          23     18-29   \n",
       "47476  Was-001383    No Arrest       Male       Black          24     18-29   \n",
       "47477  Was-001384  Arrest Made       Male       Black          17      0-17   \n",
       "\n",
       "      reported_date  reported_year reported_month reported_weekday  season  \\\n",
       "0        2010-05-04           2010            May          Tuesday  Spring   \n",
       "1        2010-02-16           2010       February          Tuesday  Winter   \n",
       "2        2010-06-01           2010           June          Tuesday  Summer   \n",
       "3        2010-01-01           2010        January           Friday  Winter   \n",
       "4        2010-01-02           2010        January         Saturday  Winter   \n",
       "...             ...            ...            ...              ...     ...   \n",
       "47473    2016-09-08           2016      September         Thursday    Fall   \n",
       "47474    2016-09-13           2016      September          Tuesday    Fall   \n",
       "47475    2016-11-14           2016       November           Monday    Fall   \n",
       "47476    2016-11-30           2016       November        Wednesday    Fall   \n",
       "47477    2016-09-01           2016      September         Thursday    Fall   \n",
       "\n",
       "              city state        lat         lon         LOCATION  POPULATION  \n",
       "0      Albuquerque    NM  35.095788 -106.538555  Albuquerque, NM      545852  \n",
       "1      Albuquerque    NM  35.056810 -106.715321  Albuquerque, NM      545852  \n",
       "2      Albuquerque    NM  35.086092 -106.695568  Albuquerque, NM      545852  \n",
       "3      Albuquerque    NM  35.078493 -106.556094  Albuquerque, NM      545852  \n",
       "4      Albuquerque    NM  35.130357 -106.580986  Albuquerque, NM      545852  \n",
       "...            ...   ...        ...         ...              ...         ...  \n",
       "47473   Washington    DC  38.828704  -77.002075   Washington, DC      687576  \n",
       "47474   Washington    DC  38.822852  -77.001725   Washington, DC      687576  \n",
       "47475   Washington    DC  38.828025  -77.002511   Washington, DC      687576  \n",
       "47476   Washington    DC  38.820476  -77.008640   Washington, DC      687576  \n",
       "47477   Washington    DC  38.866689  -76.982409   Washington, DC      687576  \n",
       "\n",
       "[47478 rows x 17 columns]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.read_csv(\"../data_cleaning/data/ml_clean_homicide_data.csv\", encoding = 'latin1')\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "b292215a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>victim_age</th>\n",
       "      <th>victim_sex</th>\n",
       "      <th>victim_race</th>\n",
       "      <th>reported_date</th>\n",
       "      <th>reported_year</th>\n",
       "      <th>reported_month</th>\n",
       "      <th>reported_weekday</th>\n",
       "      <th>season</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>POPULATION</th>\n",
       "      <th>disposition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>78</td>\n",
       "      <td>Male</td>\n",
       "      <td>Hispanic</td>\n",
       "      <td>2010-05-04</td>\n",
       "      <td>2010</td>\n",
       "      <td>May</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>Spring</td>\n",
       "      <td>Albuquerque</td>\n",
       "      <td>NM</td>\n",
       "      <td>545852</td>\n",
       "      <td>No Arrest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17</td>\n",
       "      <td>Male</td>\n",
       "      <td>Hispanic</td>\n",
       "      <td>2010-02-16</td>\n",
       "      <td>2010</td>\n",
       "      <td>February</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>Winter</td>\n",
       "      <td>Albuquerque</td>\n",
       "      <td>NM</td>\n",
       "      <td>545852</td>\n",
       "      <td>Arrest Made</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15</td>\n",
       "      <td>Female</td>\n",
       "      <td>White</td>\n",
       "      <td>2010-06-01</td>\n",
       "      <td>2010</td>\n",
       "      <td>June</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Albuquerque</td>\n",
       "      <td>NM</td>\n",
       "      <td>545852</td>\n",
       "      <td>No Arrest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32</td>\n",
       "      <td>Male</td>\n",
       "      <td>Hispanic</td>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>2010</td>\n",
       "      <td>January</td>\n",
       "      <td>Friday</td>\n",
       "      <td>Winter</td>\n",
       "      <td>Albuquerque</td>\n",
       "      <td>NM</td>\n",
       "      <td>545852</td>\n",
       "      <td>Arrest Made</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>72</td>\n",
       "      <td>Female</td>\n",
       "      <td>White</td>\n",
       "      <td>2010-01-02</td>\n",
       "      <td>2010</td>\n",
       "      <td>January</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>Winter</td>\n",
       "      <td>Albuquerque</td>\n",
       "      <td>NM</td>\n",
       "      <td>545852</td>\n",
       "      <td>No Arrest</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   victim_age victim_sex victim_race reported_date  reported_year  \\\n",
       "0          78       Male    Hispanic    2010-05-04           2010   \n",
       "1          17       Male    Hispanic    2010-02-16           2010   \n",
       "2          15     Female       White    2010-06-01           2010   \n",
       "3          32       Male    Hispanic    2010-01-01           2010   \n",
       "4          72     Female       White    2010-01-02           2010   \n",
       "\n",
       "  reported_month reported_weekday  season         city state  POPULATION  \\\n",
       "0            May          Tuesday  Spring  Albuquerque    NM      545852   \n",
       "1       February          Tuesday  Winter  Albuquerque    NM      545852   \n",
       "2           June          Tuesday  Summer  Albuquerque    NM      545852   \n",
       "3        January           Friday  Winter  Albuquerque    NM      545852   \n",
       "4        January         Saturday  Winter  Albuquerque    NM      545852   \n",
       "\n",
       "   disposition  \n",
       "0    No Arrest  \n",
       "1  Arrest Made  \n",
       "2    No Arrest  \n",
       "3  Arrest Made  \n",
       "4    No Arrest  "
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select and retain only the desired columns\n",
    "final_columns_to_keep = ['victim_age','victim_sex','victim_race', 'reported_date', 'reported_year','reported_month', 'reported_weekday', 'season', 'city', 'state', 'POPULATION', 'disposition']\n",
    "df = df1[final_columns_to_keep]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "a59b5075",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Home\\AppData\\Local\\Temp\\ipykernel_23412\\3285981948.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"disposition\"] = df[\"disposition\"].apply(lambda x: 1 if x == \"Arrest Made\" else 0)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>victim_age</th>\n",
       "      <th>victim_sex</th>\n",
       "      <th>victim_race</th>\n",
       "      <th>reported_date</th>\n",
       "      <th>reported_year</th>\n",
       "      <th>reported_month</th>\n",
       "      <th>reported_weekday</th>\n",
       "      <th>season</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>POPULATION</th>\n",
       "      <th>disposition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>78</td>\n",
       "      <td>Male</td>\n",
       "      <td>Hispanic</td>\n",
       "      <td>2010-05-04</td>\n",
       "      <td>2010</td>\n",
       "      <td>May</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>Spring</td>\n",
       "      <td>Albuquerque</td>\n",
       "      <td>NM</td>\n",
       "      <td>545852</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17</td>\n",
       "      <td>Male</td>\n",
       "      <td>Hispanic</td>\n",
       "      <td>2010-02-16</td>\n",
       "      <td>2010</td>\n",
       "      <td>February</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>Winter</td>\n",
       "      <td>Albuquerque</td>\n",
       "      <td>NM</td>\n",
       "      <td>545852</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15</td>\n",
       "      <td>Female</td>\n",
       "      <td>White</td>\n",
       "      <td>2010-06-01</td>\n",
       "      <td>2010</td>\n",
       "      <td>June</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Albuquerque</td>\n",
       "      <td>NM</td>\n",
       "      <td>545852</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32</td>\n",
       "      <td>Male</td>\n",
       "      <td>Hispanic</td>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>2010</td>\n",
       "      <td>January</td>\n",
       "      <td>Friday</td>\n",
       "      <td>Winter</td>\n",
       "      <td>Albuquerque</td>\n",
       "      <td>NM</td>\n",
       "      <td>545852</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>72</td>\n",
       "      <td>Female</td>\n",
       "      <td>White</td>\n",
       "      <td>2010-01-02</td>\n",
       "      <td>2010</td>\n",
       "      <td>January</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>Winter</td>\n",
       "      <td>Albuquerque</td>\n",
       "      <td>NM</td>\n",
       "      <td>545852</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47473</th>\n",
       "      <td>29</td>\n",
       "      <td>Male</td>\n",
       "      <td>Black</td>\n",
       "      <td>2016-09-08</td>\n",
       "      <td>2016</td>\n",
       "      <td>September</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>Fall</td>\n",
       "      <td>Washington</td>\n",
       "      <td>DC</td>\n",
       "      <td>687576</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47474</th>\n",
       "      <td>19</td>\n",
       "      <td>Male</td>\n",
       "      <td>Black</td>\n",
       "      <td>2016-09-13</td>\n",
       "      <td>2016</td>\n",
       "      <td>September</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>Fall</td>\n",
       "      <td>Washington</td>\n",
       "      <td>DC</td>\n",
       "      <td>687576</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47475</th>\n",
       "      <td>23</td>\n",
       "      <td>Male</td>\n",
       "      <td>Black</td>\n",
       "      <td>2016-11-14</td>\n",
       "      <td>2016</td>\n",
       "      <td>November</td>\n",
       "      <td>Monday</td>\n",
       "      <td>Fall</td>\n",
       "      <td>Washington</td>\n",
       "      <td>DC</td>\n",
       "      <td>687576</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47476</th>\n",
       "      <td>24</td>\n",
       "      <td>Male</td>\n",
       "      <td>Black</td>\n",
       "      <td>2016-11-30</td>\n",
       "      <td>2016</td>\n",
       "      <td>November</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>Fall</td>\n",
       "      <td>Washington</td>\n",
       "      <td>DC</td>\n",
       "      <td>687576</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47477</th>\n",
       "      <td>17</td>\n",
       "      <td>Male</td>\n",
       "      <td>Black</td>\n",
       "      <td>2016-09-01</td>\n",
       "      <td>2016</td>\n",
       "      <td>September</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>Fall</td>\n",
       "      <td>Washington</td>\n",
       "      <td>DC</td>\n",
       "      <td>687576</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>47478 rows Ã 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       victim_age victim_sex victim_race reported_date  reported_year  \\\n",
       "0              78       Male    Hispanic    2010-05-04           2010   \n",
       "1              17       Male    Hispanic    2010-02-16           2010   \n",
       "2              15     Female       White    2010-06-01           2010   \n",
       "3              32       Male    Hispanic    2010-01-01           2010   \n",
       "4              72     Female       White    2010-01-02           2010   \n",
       "...           ...        ...         ...           ...            ...   \n",
       "47473          29       Male       Black    2016-09-08           2016   \n",
       "47474          19       Male       Black    2016-09-13           2016   \n",
       "47475          23       Male       Black    2016-11-14           2016   \n",
       "47476          24       Male       Black    2016-11-30           2016   \n",
       "47477          17       Male       Black    2016-09-01           2016   \n",
       "\n",
       "      reported_month reported_weekday  season         city state  POPULATION  \\\n",
       "0                May          Tuesday  Spring  Albuquerque    NM      545852   \n",
       "1           February          Tuesday  Winter  Albuquerque    NM      545852   \n",
       "2               June          Tuesday  Summer  Albuquerque    NM      545852   \n",
       "3            January           Friday  Winter  Albuquerque    NM      545852   \n",
       "4            January         Saturday  Winter  Albuquerque    NM      545852   \n",
       "...              ...              ...     ...          ...   ...         ...   \n",
       "47473      September         Thursday    Fall   Washington    DC      687576   \n",
       "47474      September          Tuesday    Fall   Washington    DC      687576   \n",
       "47475       November           Monday    Fall   Washington    DC      687576   \n",
       "47476       November        Wednesday    Fall   Washington    DC      687576   \n",
       "47477      September         Thursday    Fall   Washington    DC      687576   \n",
       "\n",
       "       disposition  \n",
       "0                0  \n",
       "1                1  \n",
       "2                0  \n",
       "3                1  \n",
       "4                0  \n",
       "...            ...  \n",
       "47473            1  \n",
       "47474            0  \n",
       "47475            0  \n",
       "47476            0  \n",
       "47477            1  \n",
       "\n",
       "[47478 rows x 12 columns]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"disposition\"] = df[\"disposition\"].apply(lambda x: 1 if x == \"Arrest Made\" else 0)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "14571810",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Home\\AppData\\Local\\Temp\\ipykernel_23412\\1097537222.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  drop_reporteddate = df.drop('reported_date', axis = 1, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>victim_age</th>\n",
       "      <th>victim_sex</th>\n",
       "      <th>victim_race</th>\n",
       "      <th>reported_year</th>\n",
       "      <th>reported_month</th>\n",
       "      <th>reported_weekday</th>\n",
       "      <th>season</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>POPULATION</th>\n",
       "      <th>disposition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>78</td>\n",
       "      <td>Male</td>\n",
       "      <td>Hispanic</td>\n",
       "      <td>2010</td>\n",
       "      <td>May</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>Spring</td>\n",
       "      <td>Albuquerque</td>\n",
       "      <td>NM</td>\n",
       "      <td>545852</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17</td>\n",
       "      <td>Male</td>\n",
       "      <td>Hispanic</td>\n",
       "      <td>2010</td>\n",
       "      <td>February</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>Winter</td>\n",
       "      <td>Albuquerque</td>\n",
       "      <td>NM</td>\n",
       "      <td>545852</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15</td>\n",
       "      <td>Female</td>\n",
       "      <td>White</td>\n",
       "      <td>2010</td>\n",
       "      <td>June</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Albuquerque</td>\n",
       "      <td>NM</td>\n",
       "      <td>545852</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32</td>\n",
       "      <td>Male</td>\n",
       "      <td>Hispanic</td>\n",
       "      <td>2010</td>\n",
       "      <td>January</td>\n",
       "      <td>Friday</td>\n",
       "      <td>Winter</td>\n",
       "      <td>Albuquerque</td>\n",
       "      <td>NM</td>\n",
       "      <td>545852</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>72</td>\n",
       "      <td>Female</td>\n",
       "      <td>White</td>\n",
       "      <td>2010</td>\n",
       "      <td>January</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>Winter</td>\n",
       "      <td>Albuquerque</td>\n",
       "      <td>NM</td>\n",
       "      <td>545852</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47473</th>\n",
       "      <td>29</td>\n",
       "      <td>Male</td>\n",
       "      <td>Black</td>\n",
       "      <td>2016</td>\n",
       "      <td>September</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>Fall</td>\n",
       "      <td>Washington</td>\n",
       "      <td>DC</td>\n",
       "      <td>687576</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47474</th>\n",
       "      <td>19</td>\n",
       "      <td>Male</td>\n",
       "      <td>Black</td>\n",
       "      <td>2016</td>\n",
       "      <td>September</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>Fall</td>\n",
       "      <td>Washington</td>\n",
       "      <td>DC</td>\n",
       "      <td>687576</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47475</th>\n",
       "      <td>23</td>\n",
       "      <td>Male</td>\n",
       "      <td>Black</td>\n",
       "      <td>2016</td>\n",
       "      <td>November</td>\n",
       "      <td>Monday</td>\n",
       "      <td>Fall</td>\n",
       "      <td>Washington</td>\n",
       "      <td>DC</td>\n",
       "      <td>687576</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47476</th>\n",
       "      <td>24</td>\n",
       "      <td>Male</td>\n",
       "      <td>Black</td>\n",
       "      <td>2016</td>\n",
       "      <td>November</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>Fall</td>\n",
       "      <td>Washington</td>\n",
       "      <td>DC</td>\n",
       "      <td>687576</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47477</th>\n",
       "      <td>17</td>\n",
       "      <td>Male</td>\n",
       "      <td>Black</td>\n",
       "      <td>2016</td>\n",
       "      <td>September</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>Fall</td>\n",
       "      <td>Washington</td>\n",
       "      <td>DC</td>\n",
       "      <td>687576</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>47478 rows Ã 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       victim_age victim_sex victim_race  reported_year reported_month  \\\n",
       "0              78       Male    Hispanic           2010            May   \n",
       "1              17       Male    Hispanic           2010       February   \n",
       "2              15     Female       White           2010           June   \n",
       "3              32       Male    Hispanic           2010        January   \n",
       "4              72     Female       White           2010        January   \n",
       "...           ...        ...         ...            ...            ...   \n",
       "47473          29       Male       Black           2016      September   \n",
       "47474          19       Male       Black           2016      September   \n",
       "47475          23       Male       Black           2016       November   \n",
       "47476          24       Male       Black           2016       November   \n",
       "47477          17       Male       Black           2016      September   \n",
       "\n",
       "      reported_weekday  season         city state  POPULATION  disposition  \n",
       "0              Tuesday  Spring  Albuquerque    NM      545852            0  \n",
       "1              Tuesday  Winter  Albuquerque    NM      545852            1  \n",
       "2              Tuesday  Summer  Albuquerque    NM      545852            0  \n",
       "3               Friday  Winter  Albuquerque    NM      545852            1  \n",
       "4             Saturday  Winter  Albuquerque    NM      545852            0  \n",
       "...                ...     ...          ...   ...         ...          ...  \n",
       "47473         Thursday    Fall   Washington    DC      687576            1  \n",
       "47474          Tuesday    Fall   Washington    DC      687576            0  \n",
       "47475           Monday    Fall   Washington    DC      687576            0  \n",
       "47476        Wednesday    Fall   Washington    DC      687576            0  \n",
       "47477         Thursday    Fall   Washington    DC      687576            1  \n",
       "\n",
       "[47478 rows x 11 columns]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop reported date column\n",
    "drop_reporteddate = df.drop('reported_date', axis = 1, inplace=True)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "89c7e89e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['victim_age', 'victim_sex', 'victim_race', 'reported_year',\n",
       "       'reported_month', 'reported_weekday', 'season', 'city', 'state',\n",
       "       'POPULATION', 'disposition'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "ed28f77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace white space with underline in columns\n",
    "\n",
    "df.columns = df.columns.str.replace(' ', '_')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "aaf5fc9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "Male      40387\n",
      "Female     7091\n",
      "Name: victim_sex, dtype: int64\n",
      "\n",
      "5\n",
      "Black       33062\n",
      "Hispanic     6817\n",
      "White        6259\n",
      "Asian         676\n",
      "Other         664\n",
      "Name: victim_race, dtype: int64\n",
      "\n",
      "12\n",
      "July         4624\n",
      "August       4360\n",
      "June         4273\n",
      "May          4210\n",
      "September    4131\n",
      "October      4060\n",
      "December     3890\n",
      "November     3886\n",
      "April        3779\n",
      "January      3682\n",
      "March        3622\n",
      "February     2961\n",
      "Name: reported_month, dtype: int64\n",
      "\n",
      "7\n",
      "Sunday       7850\n",
      "Saturday     7619\n",
      "Monday       6853\n",
      "Friday       6446\n",
      "Tuesday      6331\n",
      "Wednesday    6256\n",
      "Thursday     6123\n",
      "Name: reported_weekday, dtype: int64\n",
      "\n",
      "4\n",
      "Summer    13257\n",
      "Fall      12077\n",
      "Spring    11611\n",
      "Winter    10533\n",
      "Name: season, dtype: int64\n",
      "\n",
      "47\n",
      "Chicago           5523\n",
      "Philadelphia      3036\n",
      "Houston           2908\n",
      "Baltimore         2827\n",
      "Detroit           2496\n",
      "Los Angeles       2196\n",
      "St. Louis         1661\n",
      "Memphis           1510\n",
      "New Orleans       1394\n",
      "Indianapolis      1321\n",
      "Washington        1308\n",
      "Las Vegas         1299\n",
      "Jacksonville      1151\n",
      "Milwaukee         1115\n",
      "Columbus          1070\n",
      "Atlanta            968\n",
      "Oakland            945\n",
      "San Antonio        825\n",
      "Birmingham         785\n",
      "Nashville          755\n",
      "Cincinnati         691\n",
      "San Francisco      663\n",
      "Charlotte          661\n",
      "Oklahoma City      653\n",
      "Pittsburgh         628\n",
      "New York           622\n",
      "Boston             605\n",
      "Tulsa              573\n",
      "Louisville         572\n",
      "Fort Worth         549\n",
      "Buffalo            510\n",
      "Fresno             480\n",
      "Miami              462\n",
      "San Diego          450\n",
      "Stockton           439\n",
      "Baton Rouge        423\n",
      "Omaha              402\n",
      "Long Beach         378\n",
      "Sacramento         370\n",
      "Minneapolis        364\n",
      "Richmond           316\n",
      "Denver             312\n",
      "Albuquerque        284\n",
      "Durham             276\n",
      "San Bernardino     274\n",
      "Savannah           230\n",
      "Tampa              198\n",
      "Name: city, dtype: int64\n",
      "\n",
      "27\n",
      "CA    6195\n",
      "IL    5523\n",
      "TX    4282\n",
      "PA    3664\n",
      "MD    2827\n",
      "MI    2496\n",
      "TN    2265\n",
      "LA    1817\n",
      "FL    1811\n",
      "OH    1761\n",
      "MO    1661\n",
      "IN    1321\n",
      "DC    1308\n",
      "NV    1299\n",
      "OK    1225\n",
      "GA    1198\n",
      "NY    1132\n",
      "WI    1115\n",
      "NC     937\n",
      "AL     786\n",
      "MA     605\n",
      "KY     572\n",
      "NE     402\n",
      "MN     364\n",
      "VA     316\n",
      "CO     312\n",
      "NM     284\n",
      "Name: state, dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#count values in each categorical columns (not numeric columns)\n",
    "\n",
    "cat_cols = df.select_dtypes(exclude=[np.number]).columns\n",
    "\n",
    "# value counts\n",
    "for col in cat_cols:\n",
    "    print(df[col].nunique())\n",
    "    print(df[col].value_counts())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "d903d9aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>victim_age</th>\n",
       "      <th>reported_year</th>\n",
       "      <th>POPULATION</th>\n",
       "      <th>disposition</th>\n",
       "      <th>victim_sex_Female</th>\n",
       "      <th>victim_sex_Male</th>\n",
       "      <th>victim_race_Asian</th>\n",
       "      <th>victim_race_Black</th>\n",
       "      <th>victim_race_Hispanic</th>\n",
       "      <th>victim_race_Other</th>\n",
       "      <th>...</th>\n",
       "      <th>state_NM</th>\n",
       "      <th>state_NV</th>\n",
       "      <th>state_NY</th>\n",
       "      <th>state_OH</th>\n",
       "      <th>state_OK</th>\n",
       "      <th>state_PA</th>\n",
       "      <th>state_TN</th>\n",
       "      <th>state_TX</th>\n",
       "      <th>state_VA</th>\n",
       "      <th>state_WI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>78</td>\n",
       "      <td>2010</td>\n",
       "      <td>545852</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17</td>\n",
       "      <td>2010</td>\n",
       "      <td>545852</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15</td>\n",
       "      <td>2010</td>\n",
       "      <td>545852</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32</td>\n",
       "      <td>2010</td>\n",
       "      <td>545852</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>72</td>\n",
       "      <td>2010</td>\n",
       "      <td>545852</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47473</th>\n",
       "      <td>29</td>\n",
       "      <td>2016</td>\n",
       "      <td>687576</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47474</th>\n",
       "      <td>19</td>\n",
       "      <td>2016</td>\n",
       "      <td>687576</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47475</th>\n",
       "      <td>23</td>\n",
       "      <td>2016</td>\n",
       "      <td>687576</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47476</th>\n",
       "      <td>24</td>\n",
       "      <td>2016</td>\n",
       "      <td>687576</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47477</th>\n",
       "      <td>17</td>\n",
       "      <td>2016</td>\n",
       "      <td>687576</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>47478 rows Ã 108 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       victim_age  reported_year  POPULATION  disposition  victim_sex_Female  \\\n",
       "0              78           2010      545852            0                  0   \n",
       "1              17           2010      545852            1                  0   \n",
       "2              15           2010      545852            0                  1   \n",
       "3              32           2010      545852            1                  0   \n",
       "4              72           2010      545852            0                  1   \n",
       "...           ...            ...         ...          ...                ...   \n",
       "47473          29           2016      687576            1                  0   \n",
       "47474          19           2016      687576            0                  0   \n",
       "47475          23           2016      687576            0                  0   \n",
       "47476          24           2016      687576            0                  0   \n",
       "47477          17           2016      687576            1                  0   \n",
       "\n",
       "       victim_sex_Male  victim_race_Asian  victim_race_Black  \\\n",
       "0                    1                  0                  0   \n",
       "1                    1                  0                  0   \n",
       "2                    0                  0                  0   \n",
       "3                    1                  0                  0   \n",
       "4                    0                  0                  0   \n",
       "...                ...                ...                ...   \n",
       "47473                1                  0                  1   \n",
       "47474                1                  0                  1   \n",
       "47475                1                  0                  1   \n",
       "47476                1                  0                  1   \n",
       "47477                1                  0                  1   \n",
       "\n",
       "       victim_race_Hispanic  victim_race_Other  ...  state_NM  state_NV  \\\n",
       "0                         1                  0  ...         1         0   \n",
       "1                         1                  0  ...         1         0   \n",
       "2                         0                  0  ...         1         0   \n",
       "3                         1                  0  ...         1         0   \n",
       "4                         0                  0  ...         1         0   \n",
       "...                     ...                ...  ...       ...       ...   \n",
       "47473                     0                  0  ...         0         0   \n",
       "47474                     0                  0  ...         0         0   \n",
       "47475                     0                  0  ...         0         0   \n",
       "47476                     0                  0  ...         0         0   \n",
       "47477                     0                  0  ...         0         0   \n",
       "\n",
       "       state_NY  state_OH  state_OK  state_PA  state_TN  state_TX  state_VA  \\\n",
       "0             0         0         0         0         0         0         0   \n",
       "1             0         0         0         0         0         0         0   \n",
       "2             0         0         0         0         0         0         0   \n",
       "3             0         0         0         0         0         0         0   \n",
       "4             0         0         0         0         0         0         0   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "47473         0         0         0         0         0         0         0   \n",
       "47474         0         0         0         0         0         0         0   \n",
       "47475         0         0         0         0         0         0         0   \n",
       "47476         0         0         0         0         0         0         0   \n",
       "47477         0         0         0         0         0         0         0   \n",
       "\n",
       "       state_WI  \n",
       "0             0  \n",
       "1             0  \n",
       "2             0  \n",
       "3             0  \n",
       "4             0  \n",
       "...         ...  \n",
       "47473         0  \n",
       "47474         0  \n",
       "47475         0  \n",
       "47476         0  \n",
       "47477         0  \n",
       "\n",
       "[47478 rows x 108 columns]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#one hot coding the categorical columns\n",
    "df2 = pd.get_dummies(df)\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "58a027bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "victim_age           int64\n",
       "reported_year        int64\n",
       "POPULATION           int64\n",
       "disposition          int64\n",
       "victim_sex_Female    uint8\n",
       "                     ...  \n",
       "state_PA             uint8\n",
       "state_TN             uint8\n",
       "state_TX             uint8\n",
       "state_VA             uint8\n",
       "state_WI             uint8\n",
       "Length: 108, dtype: object"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check the datatype for df\n",
    "df2.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "33f9cc69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(37982, 107) (37982,)\n",
      "(9496, 107) (9496,)\n"
     ]
    }
   ],
   "source": [
    "# Create our train/test set\n",
    "X = df2.drop(columns=[\"disposition\"])\n",
    "y = df2[\"disposition\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y, \n",
    "                                                    random_state=seed, \n",
    "                                                    stratify=y, test_size = .20)\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "5ff37599",
   "metadata": {},
   "outputs": [],
   "source": [
    "def doMLClassification(model, X_train, y_train, X_test, y_test):\n",
    "    # fit the model\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # predict the model\n",
    "    train_preds = model.predict(X_train)\n",
    "    test_preds = model.predict(X_test)\n",
    "    test_proba = model.predict_proba(X_test)[:,1]\n",
    "\n",
    "    # make some pretty graphs\n",
    "    print(\"TRAINING SET METRICS\")\n",
    "    print(confusion_matrix(y_train, train_preds))\n",
    "    print(classification_report(y_train, train_preds))\n",
    "    print(\"TESTING SET METRICS\")\n",
    "    print(confusion_matrix(y_test, test_preds))\n",
    "    print(classification_report(y_test, test_preds))\n",
    "\n",
    "    # ROC Curve\n",
    "    auc = roc_auc_score(y_test, test_proba)\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, test_proba)\n",
    "    plt.plot(fpr, tpr)\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(F\"AUC: {auc}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "a8b3b418",
   "metadata": {},
   "outputs": [],
   "source": [
    "#init the model\n",
    "#ada = AdaBoostClassifier(random_state=42, n_estimators = 200)\n",
    "#doMLClassification(ada, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "691b48ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING SET METRICS\n",
      "[[12806  6600]\n",
      " [ 7281 11295]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.66      0.65     19406\n",
      "           1       0.63      0.61      0.62     18576\n",
      "\n",
      "    accuracy                           0.63     37982\n",
      "   macro avg       0.63      0.63      0.63     37982\n",
      "weighted avg       0.63      0.63      0.63     37982\n",
      "\n",
      "TESTING SET METRICS\n",
      "[[3179 1673]\n",
      " [1908 2736]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.66      0.64      4852\n",
      "           1       0.62      0.59      0.60      4644\n",
      "\n",
      "    accuracy                           0.62      9496\n",
      "   macro avg       0.62      0.62      0.62      9496\n",
      "weighted avg       0.62      0.62      0.62      9496\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAHFCAYAAAAOmtghAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy88F64QAAAACXBIWXMAAA9hAAAPYQGoP6dpAABerklEQVR4nO3deVhU1f8H8PewDcjmArILbiiuKCiKmUuKW5lk5pamqUVaLlR+NSs1MyyXXErNfckt1yy3cN83xF1zQ0AFFRf2bWbO7w9/3BxnVAaBywzv1/PM09wz5975zIWYt+eee69CCCFAREREZCLM5C6AiIiIqDAx3BAREZFJYbghIiIik8JwQ0RERCaF4YaIiIhMCsMNERERmRSGGyIiIjIpDDdERERkUhhuiIiIyKQw3BA9Y+bMmVAoFKhTp47e12/evAmFQoEpU6bofX3KlClQKBS4efOmVrtGo8Hy5cvRpk0bODk5wdLSEhUrVsSbb76Jv/76CxqNpsA1z5o1CzVr1oRSqUTlypUxfvx45Obm5nv98+fPo1u3bnB2doZSqYSPjw8GDx6s1cfHxwcKhULvw9raWmebq1evhr+/P6ytreHu7o7hw4cjLS1Nq8/evXufu82jR49q9RVCYP78+QgICICDgwMqVKiAFi1aYMuWLVr90tPT0aNHD9SoUQP29vawtbVF7dq18f333yM9Pf2F++Hrr7/W+7NPSUnBxIkT0bJlS7i6usLOzg5169bFjz/+iKysLJ3t5ObmYvz48fDx8YFSqUTNmjUxa9Ysve+5fv16NGvWDOXLl0fZsmXRuHFjLF++XKff8/Z/WFiYTt+0tDQMHz4c7u7usLa2hr+/P1avXq33/XNzczFt2jTUrVsXNjY2KFu2LIKDg3H48OEC7dMNGzagZ8+eqFatGmxsbODj44PevXvj6tWrWv3y/j963qN9+/Z66yXKDwu5CyAqaRYtWgQAuHDhAo4dO4agoKBX3mZWVha6dOmCf/75Bz169MCcOXPg6uqK+/fvY/v27ejWrRvWrFmDt99+2+BtT5w4Ed988w1GjRqFkJAQnDhxAl9//TVu376NefPmvXT9PXv2oFOnTmjevDnmzp0LJycnxMXFITo6Wqvfxo0bkZ2drdUWFxeH7t27IzQ0VKt9xYoVeP/99zFw4ED8/PPPuHLlCv73v//h4sWL+Oeff3Rq+OGHH9CqVSuttmcDxtixYzFhwgSEhYVh0qRJyMrKwqxZs/Dmm29i/fr1eOeddwA8+bIWQiA8PByVK1eGmZkZ9u/fj++++w579+7Fzp079e6H06dPY8qUKXBxcdF5LS4uDtOnT0efPn0QHh4OOzs7HDhwAOPGjUNkZCQiIyOhUCik/oMHD8by5csxYcIENGrUCDt27MCwYcOQmpqKr776Suq3aNEiDBgwAF27dpWC1dKlS9G3b18kJSVhxIgRWnU0a9ZMJ1Trq/edd97BiRMnMGnSJPj6+mLlypXo2bMnNBoNevXqJfVTq9UIDQ3FwYMHMXLkSAQHByM9PR1RUVFaocWQffrjjz/C1dUVY8aMQZUqVRAfH48ffvgBDRs2xNGjR1G7dm0AgJubG44cOaJT+6ZNm/Djjz/q/E4RGUQQkeTEiRMCgOjUqZMAIAYNGqTTJyYmRgAQkydP1ruNyZMnCwAiJiZGavvkk08EALF06VK961y5ckWcOXPG4HqTkpKEtbW1+Oijj7TaJ06cKBQKhbhw4cIL109PTxdubm6iU6dOQqPRGPz+48aNEwDEzp07pTaVSiXc3NxESEiIVt8VK1YIAGLr1q1S2549ewQAsXbt2pe+l4eHh3jttde02jIzM4Wjo6Po3LnzS9cfOXKkACCuX7+u81pubq7w9/cXQ4cOFS1atBC1a9fWej0tLU2kpaXprJf3sz5w4IDUdv78eaFQKMQPP/yg1XfQoEHCxsZGPHjwQGpr1qyZ8Pb2Fmq1WmrTaDSiZs2aol69elrre3t7i06dOr30c27ZskUAECtXrtRqb9u2rXB3dxcqlUpq+/nnn4WZmZk4cuTIS7erj759evfuXZ1+t2/fFpaWlmLAgAEv3WbLli1FmTJlRHJycoFqIhJCCB6WInrKwoULAQCTJk1CcHAwVq9ejYyMjFfaZmJiIhYsWIB27dqhb9++evtUr14d9erVM3jb27dvR1ZWFvr376/V3r9/fwghsGnTpheuv3btWiQkJODLL7/UGnnIDyEEFi9ejCpVqqB169ZS+9GjR5GQkKBTU7du3WBnZ4eNGzca9D55LC0t4ejoqNVmbW0tPV7G2dkZAGBhoTtgPWnSJDx8+BATJ07Uu66trS1sbW112hs3bgwAiI+Pl9o2bdoEIYTen0lmZia2b9+u9Zns7OxgZvbfn2KFQgEHB4d8fSZ9Nm7cCDs7O3Tr1k3n/e/cuYNjx45JbTNmzMDrr7+OJk2aFOi99O3TihUr6vRzd3eHp6en1n7S5/r169i3bx/ee+89ODg4FKgmIoBzbogkmZmZWLVqFRo1aoQ6dergww8/RGpqKtauXftK292zZw9yc3PRpUuXfK/TsmXLfIWN8+fPAwDq1q2r1e7m5gYnJyfp9efZv38/gCeHJ1577TVYWVmhXLly6NmzJ+7cufPCdXfu3InY2Fh8+OGHWrXmveezYc3S0hI1a9bUW9OQIUNgYWEBBwcHtGvXDgcPHtTpM2zYMGzfvh0LFy7Eo0ePkJCQgPDwcCQnJ2Po0KE6/YUQUKlUSElJwfbt2zF16lT07NkTlSpV0up38eJFfP/995gzZw7s7Oxe+JmftXv3bgCQDrXkfX5nZ2e4urpq9c3bH09//s8++wyXLl3CxIkTcf/+fSQlJWHKlCmIiorCF198ofN++/fvh729PSwtLVGrVi1MnToVarVaq8/58+fh5+enE+Keff/4+HjcvHkTdevWxVdffQUXFxdYWFigdu3aWLp0qd7Pm999+qwbN24gNjZWaz/ps2jRIgghMHDgwBf2I3opOYeNiEqSZcuWCQBi7ty5QgghUlNThZ2dnWjevLlWP0MPS02aNEkAENu3b893La1btxbm5uYv7Tdo0CChVCr1vubr66tzaOhZ7dq1EwBE2bJlxciRI8Xu3bvF3LlzRYUKFUS1atVEenr6c9ft3r27MDc3F7du3dJqnzhxogAgEhISdNYJCQkRvr6+0vKpU6fEsGHDxMaNG8X+/fvFokWLhJ+fnzA3N9e7v+bOnSuUSqUAIACI8uXLi8jISL31rVq1SuoHQPTv31/k5uZq9VGr1SIoKEj07NlTatN3WEqfM2fOCBsbGxEaGqrV3rZtW1GjRg2961hZWekcQty0aZNwdHSU6rSxsRG///67zrqDBw8WixYtEvv27RObNm0SvXv3FgDE+++/r9WvevXqol27djrr37lzRwCQDpcdOXJEABAODg6iVq1a4o8//hA7duwQ7777rgAg5s2bp7ON/OzTZ+Xm5oqWLVsKBwcHERcX99x+KpVKeHh4iJo1a75we0T5wXBD9P9atGghbGxsxOPHj6W2/v37CwDiypUrUltxhJv8GjRokLC2ttb7mq+vr94vuae1bdtWABAff/yxVvumTZsEADF//ny96z148EAolUq9c0Dywk1iYqLOayEhIc/94s/z6NEj4enpqTPnZNGiRUKpVIrPP/9c7Ny5U2zdulX06NFDlClTRu++ffjwoThx4oTYvXu3mDhxonBwcBCdO3fWmt8yefJkUb58ea15IvkJNzExMcLLy0v4+vpqzaER4sk+fd4XtJWVlda+3rZtm7CzsxP9+/cX27ZtE5GRkeKzzz4TFhYWYtGiRS+sQQghPv30UwFAnDp1SmqrXr26aN++vU7fvHATEREhhBDi0KFDAoCwsrISN2/elPppNBrRsGFD4enpqbON/OzTp2k0GtG3b19hbm4uNm3a9MLP8vfff7/w/ysiQzDcEAkhrl69KhQKhXj33XfFo0ePpEfe5MxRo0ZJfePj4wUAMWnSJL3bioiIEACkEY2VK1cKAGLOnDmFXveoUaMEAL0jLE5OTlojEvr06NFDABAbNmzQas/MzBQKhUJ88sknetebMWOGACA2btyo89rcuXMFAL2TmQMDA0XTpk1fWJMQQoSFhQkAIiMjQwjx5EvVxsZGDBkyRKdvixYthI+Pz0u3uXr1aq3PGhsbK2xsbMSMGTO0fubNmjUTfn5+4tGjR9L7P+3mzZvCx8dHVK5cWcTHx+u83qNHD+Hs7KzTnpaWJgCI0aNHCyGefPG7ubmJjh076vTt27evsLW11TuJ+WlHjx4VAMTs2bOltiZNmohGjRrp9D1//rwAIH777TchhBCXL18WAHRCpBBCjB49WgDQOzn4ac/u06dpNBrx4YcfCjMzM7F8+fIXbkcIIUJDQ4WlpeVL35MoPzjnhgj/Hetft24dypUrJz06deoEAFi6dKk0t8HJyQnm5ua4ffu23m3dvn0b5ubmqFChAgCgVatWsLS0fOnk3oLIm2tz7tw5rfbExEQkJSU991o9eV42ifnpia5PW7hwIVxcXPDmm2/muyaVSoXLly+/tCbgydwOANJcnn///ReZmZlo1KiRTt/AwEDcvHlT5xo6z8qb/HvlyhUAT+aBZGZmYtiwYVo/80OHDuHSpUsoV64cRo8erbWN2NhYtGzZEkII7NmzB56enno///3795GYmKjVnrc/8j7/3bt3kZCQINX1tEaNGiE9PV3nWknPyttPT/+c6tati0uXLkGlUr3w/atWrYoyZcrke7v6PLtPn15/4MCBWLx4MRYsWID333//hdu5d+8e/v77b3Tu3FnvhGQig8mZrIhKApVKJdzd3UXVqlXFnj17dB6ff/65ACD++usvaZ3XX39deHt7i8zMTK1tZWZmikqVKokWLVpotb/sVPBr164V6FTwBw8eCGtraxEWFqbVHhERka9TwS9duiQUCoXOKe8bNmwQAPT+izvvdPmRI0fq3WbeqeDPHhrJm6+xbdu2F9b08OFD4eHhIfz9/aW22NhYAUDnc2o0GtGsWTNRrly5l57KvnDhQgFArFu3Tgjx5PCXvp93/fr1hY+Pj9izZ4+4evWqVg0+Pj7Cy8tL7+nkefJOBX92ZO/jjz/WOhU8KytLWFtb6z2E1KtXL2FmZqZzyOtZeb9Xp0+fltq2bt0qAIjVq1dr9W3fvr3OqeA9e/YUlpaWWpct0Gg0wt/fX1StWvWF7y2E7j7NW3/AgAFCoVDonbejT96h3KcvE0D0KhhuqNT766+/BADx448/6n39/v37QqlUii5dukhthw8fFkqlUvj7+4slS5aI3bt3iyVLlgh/f3+hVCrF4cOHtbaRmZkp2rVrJxQKhejVq5dYu3at2L9/v9iwYYP45JNPhLW1tdachPxOKBZCiO+//14oFArx1Vdfib1794rJkycLpVKpE1iWLl0qzM3NdQLWp59+KszMzER4eLiIjIwUv/76qyhXrpxo0KCByM7O1nm/vENG//7773NrWr58uQAgPvroI7Fnzx4xb948UbZsWdG2bVutfj179hT/+9//xNq1a6V+NWrUEBYWFjoThd955x1hZmYmhg0bJnbs2CE2b94sunbtKgCICRMmSP3mzp0revfuLZYuXSp2794t/vrrLzFy5EhhY2MjgoODXzoBVt+cm7t374oqVaoIpVIpfv/9d3HkyBGtx7OHpwYOHCiUSqWYPHmy2Lt3r/jqq6+EQqEQEydO1OoXHh4uAIg+ffqIv//+W2zbtk18/PHHAoDWNWFWrFghunbtKhYtWiR27dol1q9fLx1S7Nevn85naNu2rShXrpyYN2+e2L17txg0aJAAoDNR+dq1a6Js2bKiRo0aYtWqVWLLli0iNDRUKBQKrWsPGbJP8+YBffjhhzr76em5QU+rWbOm8PLyeu7cHSJDMdxQqdelSxdhZWUl7t2799w+PXr0EBYWFlqTZE+ePClCQ0OFk5OTMDc3F05OTiI0NFRERUXp3YZKpRJLly4VrVu3FuXLlxcWFhbC2dlZdOjQQaxcuVLrD3uLFi2EIQOrM2bMEL6+vsLKykpUqlRJjB07VuTk5Gj1Wbx4sQAgFi9erFPXpEmTRLVq1YSlpaVwc3MTn3zyiXj06JHO+2RkZAhHR0fx+uuvv7SmlStXinr16gkrKyvh6uoqhg4dKlJTU7X6RERECH9/f+Ho6CjMzc2Fs7OzCA0NFcePH9fZXmZmppg8ebKoV6+esLe3F+XLlxdNmjQRv//+u9aozaFDh8Sbb74p3N3dhZWVlShTpoyoX7++mDBhwgvP/sqjL9zkXWzweY+xY8dq9c/JyRFjx44VlSpVElZWVsLX11fMnDlT573UarWYP3++CAwMFGXLlhUODg6iQYMG4pdfftH6+R05ckS88cYbwtXVVVhaWooyZcqIRo0aidmzZ+sNBKmpqWLo0KHC1dVVWFlZiXr16olVq1bp/bznzp0TnTp1Evb29sLa2lo0adJEa5TS0H3q7e393P3k7e2t8/55E5u//fZbvfURFYRCiP8/uEpERERkAjihmIiIiEwKww0RERGZFIYbIiIiMikMN0RERGRSGG6IiIjIpDDcEBERkUmxkLuA4qbRaHDnzh3Y29tLl3YnIiKikk0IgdTUVLi7u7/01iClLtzcuXMHXl5ecpdBREREBRAfH6/3vm5PK3Xhxt7eHsCTnePg4CBzNURERJQfKSkp8PLykr7HX6TUhZu8Q1EODg4MN0REREYmP1NKOKGYiIiITArDDREREZkUhhsiIiIyKQw3REREZFIYboiIiMikMNwQERGRSWG4ISIiIpPCcENEREQmheGGiIiITArDDREREZkUWcPN/v378dZbb8Hd3R0KhQKbNm166Tr79u1DQEAArK2tUaVKFcydO7foCyUiIiKjIWu4SU9PR/369fHLL7/kq39MTAw6duyI5s2bIzo6Gl999RWGDh2K9evXF3GlREREZCxkvXFmhw4d0KFDh3z3nzt3LipVqoTp06cDAPz8/HDy5ElMmTIFXbt2LaIqiYiI6EU0GoFslQZZuWpkqdRQqQW8ypeRrR6juiv4kSNHEBISotXWrl07LFy4ELm5ubC0tNRZJzs7G9nZ2dJySkpKkddJRERkzIQQOHA1CdvOJ+DinRSULWP1/8FFg+xcNTJz1U+Wc58EmmyVRmt9d0drHB79hkzVG1m4SUxMhIuLi1abi4sLVCoVkpKS4ObmprNOREQExo8fX1wlEhERGZ1TcY9wOSEVMUlpuJiQgptJGbj9OLNA27I0V8DcXFHIFRrGqMINACgU2jtMCKG3Pc/o0aMRHh4uLaekpMDLy6voCiQiIirh0rNVOB7zEJcTU7H6RBxiH2To9LG2NENoAw9UsFXC2tIMPk62sLYwh7WlOawtzf7/v888tzCDhbn8J2IbVbhxdXVFYmKiVtu9e/dgYWGBChUq6F1HqVRCqVQWR3lEREQlUkxSOnZduosTNx8i9kEGrt9PQ65a6PTrUMcVLWs4w6NsGdRyd0B5WysZqn11RhVumjZtir/++kur7Z9//kFgYKDe+TZERESl2cP0HDT5YRdy1Bqd1zzL2aBhpXKo5+mIzv7uqGhvLUOFRUPWcJOWloZr165JyzExMTh9+jTKly+PSpUqYfTo0bh9+zaWLVsGAAgLC8Mvv/yC8PBwDBo0CEeOHMHChQuxatUquT4CERFRiZCtUuNyQipOxj7C5YQUrD91C5pnBmf+174marjaoXpFe3iWs3nulA5jJ2u4OXnyJFq1aiUt582N+eCDD7BkyRIkJCQgLi5Oer1y5crYunUrRowYgV9//RXu7u6YOXMmTwMnIqJSKVetwa5L9zBx60XceZwF9bNpBoCVuRk61HXFtPf8YW5mmmHmWQqRNyO3lEhJSYGjoyOSk5Ph4OAgdzlERET5plJr8O/dVCw6eBP/3k3B+du6lzdpWcMZtd0d4OfmgDrujvBxspWh0sJnyPe3Uc25ISIiKm2EEFhzIh5bzyci6uZDpOeodfr0bOyFQO/yCG3gAbNSMjrzIgw3REREJVBSWja2nU/Er7uvITElS2q3U1qgor0Sr/s6Y8BrleFe1qbUHG7KL4YbIiIiGak1ArcfZeL6/TRcv5+G+Qdu4G5Ktk6/ivZKLPygEWq7O3B05iUYboiIiIpJalYurtxNxfV76bh2Pw037qdj56W7z+1vY2mOoW9UR2gDD7g6ms6p2kWN4YaIiKgI5ag0+GbTeey4mIi0LBVUes5oAoDytlYoY2WO9wK94ONki3oejvCuUMZkT9cuSgw3RERERWTbuQR8suKUVpurgzWqVbRDtYp28KlQBrXcHVHHwwFlrPiVXFi4J4mIiApJVq4aey7fw/GbD7H/yn1cv5+u9fr6T4IR4F1OpupKD4YbIiKiV3TrUQZm772OzafvIC1bpfVaXQ9HrPqoCeyU/MotLtzTREREBspRaXA5MQVnbiXjnwuJOHA1SXrN3dEaIbVdUd3FDpWdbNHYp3yJuFN2acJwQ0RE9AL3U7MR/ygDd5OzcDkxFTN2XX1u36UfNkbzak48VVtmDDdERETPSM9WYcvZBKw4Hocz8Y+f2+91X2fU93REw0rlEFytApQW5sVXJD0Xww0RERGeXEzv2r00rDoeh7Un43Vuc+DvVRZVnGzR0Lsc6no4op6nI0/TLqEYboiIqFSLin2ID5ecRHJmrla7T4Uy6N6oEro29EBFB15Az5gw3BARUamTo9Jgx4VEjN5wTufsJn+vsugX7IO3/d05MmOkGG6IiKhUEELg6I2HiNh2CWdvJeu8vrhfI7zu68ybUJoAhhsiIjJJGo3AoetJWH08HlYWZthyNgE5ao1WnwaVyuLLdjXQtEoFjtKYEIYbIiIyKSduPsTfZ+5g6ZHY5/apVL4Mln3YGD5OtsVYGRUXhhsiIjJaQghcvZeGYzce4GTsI/x5+o7efv5eZdEt0BNBlSugWkW7Yq6SihvDDRERGY1ctQb/JqbiVNwjrDwWh8uJqXr71fVwRPs6rujT1BsO1pbFXCXJjeGGiIhKtOTMXFy4k4x1J29hQ/RtvX1quzugVY2KqOJsCzdHGzStWqGYq6SShOGGiIhKnKxcNTafuYOFB2Lw713d0Zl6no5oXt0Jtdwc0aKGM29KSVr420BERCWCEALX76dh5q5r2HxGd+5Mx7qu6NGoEppVc+Lp2vRCDDdERCSrh+k5WB91CyuOxeLmgwyt1z5rXQ11PRzRpGoFzp2hfGO4ISIiWZyOf4wuvx7SajNTAE2rVoCTnRKft62BShXKyFQdGTOGGyIiKlb/JqZi3v4bWH/qllb7qA410bm+O9zL2shUGZkKhhsiIipyGo3AkRsP8M2m87iRlK712metq2F4G1/Oo6FCw3BDRERFKiNHhVrf7tBpn9KtPt6s5wZrS3MZqiJTxnBDRESFTgiBFcfisOVsAo7ceCC1d/F3xxt+LuhY140jNVRkGG6IiKjQnIp7hKM3HuCn7f/qvNbGzwXTezSQoSoqbRhuiIioUAxeEYWt5xK12jzK2uCrjn5oVq0CypaxkqkyKm0YboiI6JVExT5E1zlHtNrGvVULneq5w9leKVNVVJox3BARkcESk7Ow7XwC1pyI17p5pZOdFY6OfgMW5mYyVkelHcMNERHlS0aOClvOJuDLdWf1vn5kdGu4OfIaNSQ/hhsiInoulVqD3guO4VjMQ72vfxHiC49yNniznjssOVpDJQTDDRER6bh+Pw0DlpzQudcTAAR6l8Pb/u7o09Sn+AsjygeGGyIiAgDkqDRYf+oWJvx9ERk5aq3XPMraYGJoHbTwdYZCwevTUMnGcENERFh4MAbz9l/H3ZRsrfYfu9bFOw09eciJjArDDRFRKXUvJQv9l5zAhTspUpuTnRV6BXmjXW0X1HZ3lLE6ooJjuCEiKmWu3E1F1zmHkZql0nnt4P9a815PZPQYboiISomTNx9i5bE4bIi+rdXeO6gSwlpUhWc5G86nIZPAcENEZOLO3nqMkevOal1sz9fFDsFVnfB1Jz9ecI9MDsMNEZEJEkKgxeS9UCiA2GdO5/6qY00Mal6FozRkshhuiIhMSGaOGsuO3ETEtss6r73TwAMTutSBrZJ/+sm08TeciMhEnL31GL0XHNOZKLz78xao4mwnU1VExY/hhojIyAkhkJiShW5zjyBbpQEANKtWAZ+H1EADr7I8/ESlDsMNEZER+2DRcVy4k4KktP8uvrdtWHP4uTnIWBWRvBhuiIiM1Htzj+D4zf9uaGlrZY7vQ+sw2FCpx3BDRGREUrNysevSPQxfc1qr/dy4ENgpLXgIiggMN0RERkGl1mDm7muYueuqzmuXJ7TnVYWJnsJwQ0RUwt1+nIlWU/Yi5/8nCwOAZzkbDHujOroFeslYGVHJxHBDRFQCCSEwe+91nL31GDsu3JXa63uVxYzu/vBxspWxOqKSjeGGiKiEOX87GW/OOqjTvqhfIFrXdJGhIiLjwnBDRFRCRMc9wg9bL+HEzUda7csHNEZQ5QqwsuA9oIjyg+GGiEhm524l461ftEdqFApg7xct4V2Bh5+IDMVwQ0Qkk0UHYzBv/w0kpmRJbfU8HdG9kRd6B3nLWBmRcWO4ISIqZnceZ6L99P1IeeYeUPP7BqJtLc6pIXpVsh/AnT17NipXrgxra2sEBATgwIEDL+y/YsUK1K9fH2XKlIGbmxv69++PBw8eFFO1RESv5nFGDoIn7ZaCjYO1BSa/Ww/Xf+jIYENUSGQNN2vWrMHw4cMxZswYREdHo3nz5ujQoQPi4uL09j948CD69u2LAQMG4MKFC1i7di1OnDiBgQMHFnPlRET5l61S49c919B7wVH4fxcptb9RsyLOjmuHboFeMDfjlYWJCotCCCHkevOgoCA0bNgQc+bMkdr8/PzQpUsXRERE6PSfMmUK5syZg+vXr0tts2bNwk8//YT4+Ph8vWdKSgocHR2RnJwMBwfef4WIis71+2n4eHkUrt1L03mtnqcj/hzSjLdLIMonQ76/ZZtzk5OTg6ioKIwaNUqrPSQkBIcPH9a7TnBwMMaMGYOtW7eiQ4cOuHfvHtatW4dOnTo9932ys7ORnf3f3XJTUlIK5wMQET3HtXtpeO+3I3iYnqPVXq2iHTrUccWHzSqjnK2VTNURmT7Zwk1SUhLUajVcXLSPMbu4uCAxMVHvOsHBwVixYgW6d++OrKwsqFQqdO7cGbNmzXru+0RERGD8+PGFWjsRkT7jNl/An6dv41FGrlZ7v2AfDH2jOsoz0BAVC9knFD87JCuEeO4w7cWLFzF06FB8++23iIqKwvbt2xETE4OwsLDnbn/06NFITk6WHvk9fEVElF9CCKw8Foclh29Kwcbfqyxa1XDG5QntMa5zbQYbomIk28iNk5MTzM3NdUZp7t27pzOakyciIgLNmjXDl19+CQCoV68ebG1t0bx5c3z//fdwc3PTWUepVEKpVBb+ByAiAnAvJQvfb7mEzWfuAADslBY4NKo1HG0sZa6MqPSSLdxYWVkhICAAkZGRCA0NldojIyPx9ttv610nIyMDFhbaJZubmwN48i8nIqLikJWrxtx913H+dgp2Xb6LvD8/PRtXwndv14alueyD4kSlmqwX8QsPD0efPn0QGBiIpk2bYt68eYiLi5MOM40ePRq3b9/GsmXLAABvvfUWBg0ahDlz5qBdu3ZISEjA8OHD0bhxY7i7u8v5UYiolNh2LgGfrDil1eZoY4lJ79RF+zquPPuJqASQNdx0794dDx48wHfffYeEhATUqVMHW7duhbf3k8uOJyQkaF3zpl+/fkhNTcUvv/yCzz//HGXLlkXr1q3x448/yvURiKgU0GgEpkVewZZzCYhJSpfaa7jYY3CrquhU1w0WHK0hKjFkvc6NHHidGyLKr1y1BuF/nMFf/z+fJo+bozUmv1sfr1V3kqkyotLHKK5zQ0RUEkXFPsSKo3G4nJiK+IcZSM3Wvv/Tmo+aIKhKBZmqI6L8YLghIvp/P0dewYxdV7XalBZmcHO0xu8Dg+BZroxMlRGRIRhuiIgAbD2XoBVsOtd3x2vVndCxrhvslPxTSWRM+H8sEZV6f56+jWGrT0vLp75py4vuERkxhhsiKrWyVWrM2HkVs/f+dzPe5QMaM9gQGTmGGyIqdZIzczFp22Vsir6NzFy11H5mbAivLExkAhhuiKjUSEjOROsp+7QCDQD0aOSF0R39GGyITATDDRGVCkeuP0DP+Uel5XJlLDGweRUMbF4ZSgtzGSsjosLGcENEJm/c5gtYcvimtDy6Q0183KKqfAURUZFiuCEik6TRCPxxMh7f/Hkeuer/LsR+7Ks34OJgLWNlRFTUGG6IyORcu5eKd2YfRkrWf1cXruvhiMX9G8HJTiljZURUHBhuiMgkZOaosehQDNaciEfcwwyp3c/NAT+E1oG/V1nesZuolGC4ISKjJYTAzkv38PvRWOy7cl/rtYaVymJMJz8EeJeXqToikgvDDREZpdgH6Ri07CSu3E3Tam9WrQJGd/BDbXcHjtQQlVIMN0RkVIQQmL33Oibv+Fdqq+XmgAldaqNhpXIMNETEcENExiM9W4XaY3dotU17rz7eaegpU0VEVBIx3BBRiZeWrcKyIzfx0/b/RmvMFMCxr9rA2Z5nPxGRNoYbIirRYh+ko8XkvVpt1pZmuDyhgzwFEVGJx3BDRCWSEAIT/r6ERYdipLa6Ho74qqMfmlatIGNlRFTSMdwQUYlz7V4q3vvtKB6m50ht375ZCx++VlnGqojIWDDcEFGJkpWrRptp+6Xlt+q7Y2q3+rCyMJOxKiIyJgw3RFRiCCFQ85vt0vLi/o3QqkZFGSsiImPEfwoRUYkghECTiF3Scq+gSgw2RFQgDDdEVCKsPB6HuynZ0vLELnVkrIaIjBkPSxGRrDJz1Bi6OhqRF+8CAHoHVcLE0LoyV0VExozhhohkIYTA6hPxGL3hnNTmbK/Ed29zxIaIXg3DDREVu9SsXLT7eT/uJGdJbVWcbbGgbyDMzXhvKCJ6NQw3RFRs1BqBufu0b3pZ1dkWs3o2RC13BxkrIyJTwnBDRMWm+29HcDL2kbT8zZu1MIAX5iOiQsZwQ0TFIir2oRRsOtRxxegOfqhUoYzMVRGRKWK4IaIip9EIhP1+Slqe3bshFArOrSGiosFwQ0RF6srdVIT8/N/tFOb3DWSwIaIixYv4EVGRUWuEVrCp7e6AtrVcZKyIiEqDAo3cqFQq7N27F9evX0evXr1gb2+PO3fuwMHBAXZ2doVdIxEZoan//Islh29Ky5w8TETFxeBwExsbi/bt2yMuLg7Z2dlo27Yt7O3t8dNPPyErKwtz584tijqJyEhoNAIfLD6OA1eTpLZJ79RFj8aVZKyKiEoTgw9LDRs2DIGBgXj06BFsbGyk9tDQUOzatesFaxKRqbuUkIIqX22Vgo21pRlWDgpisCGiYmXwyM3Bgwdx6NAhWFlZabV7e3vj9u3bhVYYERmPJYdisPH0HZyJfyy1dajjyrOiiEgWBocbjUYDtVqt037r1i3Y29sXSlFEZDzm77+BiVsvabVN7VYfXQM8ZaqIiEo7g8NN27ZtMX36dMybNw8AoFAokJaWhrFjx6Jjx46FXiARlUzX7qWizbT9Wm0rBgahWTUnmSoiInpCIYQQhqxw584dtGrVCubm5rh69SoCAwNx9epVODk5Yf/+/ahYsWJR1VooUlJS4OjoiOTkZDg48F42RAURse0S5u2/gby/Hm38KmLu+wGwMOfVJYioaBjy/W3wyI27uztOnz6N1atXIyoqChqNBgMGDEDv3r21JhgTkemJe5CB1yfvkZaDKpfHsDbVEVyVozVEVHIYPHKzf/9+BAcHw8JCOxepVCocPnwYr7/+eqEWWNg4ckNUMMuPxuKbTee12q5N7MDRGiIqFkU6ctOqVSskJCToHH5KTk5Gq1at9E42JiLjlZatQq/5R3H2VrLU9kNoXfQK4undRFQyGRxuhBB6T+188OABbG1tC6UoIioZdl68i4HLTmq1Xfm+A6wsOFpDRCVXvsPNO++8A+DJ2VH9+vWDUqmUXlOr1Th79iyCg4MLv0IiksWP2y9jzt7r0nLHuq6Y3r0Bgw0RlXj5DjeOjo4Anozc2Nvba00etrKyQpMmTTBo0KDCr5CIitXjjBx88+cF/HXmDgDgvUBPfNyiKqo6875xRGQc8h1uFi9eDADw8fHBF198wUNQRCZo35X76Lf4uHSKd/dAL/z4bj15iyIiMpDBZ0sZO54tRaRLCIFPfj+F7RcSpbbP2/ri09bVePsEIioRivRsKQBYt24d/vjjD8TFxSEnJ0frtVOnThVkk0Qkk0sJKZj6z7/Yeeme1Lb3i5bwceLoLBEZJ4NnBs6cORP9+/dHxYoVER0djcaNG6NChQq4ceMGOnToUBQ1ElEREEJg4cEYdJhxQAo2Y9+qhZiIjgw2RGTUDB65mT17NubNm4eePXti6dKlGDlyJKpUqYJvv/0WDx8+LIoaiaiQpWWr8PHykzh07QEAwMHaAks+bIyGlcrJXBkR0aszeOQmLi5OOuXbxsYGqampAIA+ffpg1apVhVsdERW6FcdiUWfsDinYtKrhjFPftGWwISKTYfDIjaurKx48eABvb294e3vj6NGjqF+/PmJiYlDK5iYTGZV9V+5j0NKTyFFrpLaJoXXQO8hbxqqIiAqfweGmdevW+Ouvv9CwYUMMGDAAI0aMwLp163Dy5EnpQn9EVLJ8//dFLDgYIy2/7e+OH7vWg7WluYxVEREVDYNPBddoNNBoNNKNM//44w8cPHgQ1apVQ1hYGKysrIqk0MLCU8GpNBFCoPLordJyGStzTOpaD53ru8tYFRGR4Qz5/i7U69zcvn0bHh4ehbW5IsFwQ6VBRo4K3X87inO3k7XaL09oz9EaIjJKhnx/F8pNYhITE/HZZ5+hWrVqBq87e/ZsVK5cGdbW1ggICMCBAwde2D87OxtjxoyBt7c3lEolqlatikWLFhW0dCKTs//KfdT6dodWsHGys8LNSZ0YbIioVMh3uHn8+DF69+4NZ2dnuLu7Y+bMmdBoNPj2229RpUoVHD161OCQsWbNGgwfPhxjxoxBdHQ0mjdvjg4dOiAuLu6567z33nvYtWsXFi5ciH///RerVq1CzZo1DXpfIlMkhMCXa8+g76LjUluvoEo4+XUbnPy6rYyVEREVr3wflho8eDD++usvdO/eHdu3b8elS5fQrl07ZGVlYezYsWjRooXBbx4UFISGDRtizpw5Upufnx+6dOmCiIgInf7bt29Hjx49cOPGDZQvX97g9wN4WIpM18ClJ7SuMjz3/QC0r+MqY0VERIWnSA5LbdmyBYsXL8aUKVOwefNmCCHg6+uL3bt3FyjY5OTkICoqCiEhIVrtISEhOHz4sN51Nm/ejMDAQPz000/w8PCAr68vvvjiC2RmZj73fbKzs5GSkqL1IDI1m6JvawWb8+PbMdgQUamV71PB79y5g1q1agEAqlSpAmtrawwcOLDAb5yUlAS1Wg0XFxetdhcXFyQmJupd58aNGzh48CCsra2xceNGJCUlYfDgwXj48OFzD4lFRERg/PjxBa6TqKRbezIeX647Ky3f+KEjzMx4s0siKr3yPXKj0WhgaWkpLZubm8PW9tXvP/PsHYeFEM+9C7FGo4FCocCKFSvQuHFjdOzYEdOmTcOSJUueO3ozevRoJCcnS4/4+PhXrpmopNhz+Z5WsDkyujWDDRGVevkeuRFCoF+/flAqlQCArKwshIWF6QScDRs25Gt7Tk5OMDc31xmluXfvns5oTh43Nzd4eHjA0dFRavPz84MQArdu3UL16tV11lEqlVLNRKZCCIEJf1/CokP/XZjvwMhWcHO0kbEqIqKSId/h5oMPPtBafv/991/pja2srBAQEIDIyEiEhoZK7ZGRkXj77bf1rtOsWTOsXbsWaWlpsLOzAwBcuXIFZmZm8PT0fKV6iIyFEAI1vtmOHNV/t1HYPrw5vMqXkbEqIqKSo1Av4meoNWvWoE+fPpg7dy6aNm2KefPmYf78+bhw4QK8vb0xevRo3L59G8uWLQMApKWlwc/PD02aNMH48eORlJSEgQMHokWLFpg/f36+3pNnS5GxC19zGhuibwMAGvmUwx8fN33uoVwiIlNhyPe3wfeWKkzdu3fHgwcP8N133yEhIQF16tTB1q1b4e395EZ+CQkJWte8sbOzQ2RkJD777DMEBgaiQoUKeO+99/D999/L9RGIio1GI7DyeJwUbBQKYG1YsMxVERGVPLKO3MiBIzdkjP48fRvDVp+Wln0qlMGmIc1QtkzJvpcbEVFhMZqRGyJ6MSEEZuy6iuk7r0ptLWs446eu9RhsiIieg+GGqIS6di8Vbabt12pb0r8RWtaoKFNFRETGgeGGqAQ6cPU++iz87x5R7zTwwIi2vjwjiogoHwp0V/Dly5ejWbNmcHd3R2xsLABg+vTp+PPPPwu1OKLS6MrdVK1gs/qjJpjW3Z/BhogonwwON3PmzEF4eDg6duyIx48fQ61WAwDKli2L6dOnF3Z9RKXKymNxCPn5v0NRR0a3RpMqFWSsiIjI+BgcbmbNmoX58+djzJgxMDc3l9oDAwNx7ty5Qi2OqLS4nJiCmt9sw1cb//t/aN+XLXnFYSKiAjB4zk1MTAwaNGig065UKpGenl4oRRGVFhqNQO2xO5CZq9ZqP/i/VvAsx8NQREQFYfDITeXKlXH69Gmd9m3btkl3DSeilxNCYPCKU1rBpm9Tb8REdGSwISJ6BQaP3Hz55ZcYMmQIsrKyIITA8ePHsWrVKkRERGDBggVFUSORybmbkoU3pu5DWrYKAPB+k0qY8HYd3kaBiKgQGBxu+vfvD5VKhZEjRyIjIwO9evWCh4cHZsyYgR49ehRFjUQm5dnr1wRVLo/vu9SVsSIiItPySrdfSEpKgkajQcWKxnNRMd5+geQU9yADr0/eIy3XdLXHtmHNOWJDRPQShnx/GzznZvz48bh+/ToAwMnJyaiCDZGclh+N1Qo207v7Y/vw1xlsiIgKmcHhZv369fD19UWTJk3wyy+/4P79+0VRF5HJuJeahU4zD+CbTeelthk9/NGlgYeMVRERmS6Dw83Zs2dx9uxZtG7dGtOmTYOHhwc6duyIlStXIiMjoyhqJDJa1++nofHEXbhwJwXAk8NQh0a1xtv+DDZEREXllebcAMChQ4ewcuVKrF27FllZWUhJSSms2ooE59xQcQqO2IU7yVkAgHa1XfBbn0CZKyIiMk6GfH+/8o0zbW1tYWNjAysrK6Smpr7q5ohMQkJyJppG7JaWVwwMQrNqTjJWRERUehToxpkxMTGYOHEiatWqhcDAQJw6dQrjxo1DYmJiYddHZHTSslVoM3WfVltwVd4fioiouBg8ctO0aVMcP34cdevWRf/+/aXr3BARkJ6twog1p5Ge8+Sqw5PeqYv3Ar14RhQRUTEyONy0atUKCxYsQO3atYuiHiKjtevSXQxYelJarl7RDj0aV5KxIiKi0umVJxQbG04opqJw5PoD9Jx/VFpuXbMi5vUJgIV5gY78EhHRMwp9QnF4eDgmTJgAW1tbhIeHv7DvtGnT8l8pkQn4aftlzN57XVr+uXt9hDbwlLEiIqLSLV/hJjo6Grm5udJzInriyPUHWsFmTu+G6FDXTcaKiIiIh6WICuhmUjpaTtkL4MnF+daGNYW9taW8RRERmagivbfUhx9+qPd6Nunp6fjwww8N3RyRUVp7Ml4KNvbWFgw2REQliMHhZunSpcjMzNRpz8zMxLJlywqlKKKSbMzGc/hy3VlpecXAIAYbIqISJN+ngqekpEAIASEEUlNTYW1tLb2mVquxdetW3iGcTN6ef+9hxbE4afncuBAGGyKiEibf4aZs2bJQKBRQKBTw9fXVeV2hUGD8+PGFWhxRSZGRo8IbU/ch4f/vEwUAVyd2gCVP9SYiKnHyHW727NkDIQRat26N9evXo3z58tJrVlZW8Pb2hru7e5EUSSSn+ftvYOLWS1pt+75syWBDRFRC5TvctGjRAsCT+0pVqlSJl5OnUiFi2yX8tu+GtFzLzQEbBgfD2tJcxqqIiOhF8hVuzp49izp16sDMzAzJyck4d+7cc/vWq1ev0IojktOaE3FawebAyFbwKl9GxoqIiCg/8hVu/P39kZiYiIoVK8Lf3x8KhQL6Lo+jUCigVqsLvUii4qTWCEzfeQWzdl+T2qK+boMKdkoZqyIiovzKV7iJiYmBs7Oz9JzIlC05fFMr2Oz/shWDDRGREclXuPH29tb7nMjUHLqWhCk7/pWWT3/bFmXLWMlYERERGapAF/HbsmWLtDxy5EiULVsWwcHBiI2NLdTiiIpT2PIo9F5wDJm5avi62OHEmDYMNkRERsjgcPPDDz/AxsYGAHDkyBH88ssv+Omnn+Dk5IQRI0YUeoFExWHZkZvYfiERAFDV2RabP30NzvY8FEVEZIzyfSp4nvj4eFSrVg0AsGnTJrz77rv46KOP0KxZM7Rs2bKw6yMqcjeT0vHtnxek5a3DmkNpwVO9iYiMlcEjN3Z2dnjw4AEA4J9//kGbNm0AANbW1nrvOUVUku27cl+6ASYAXPyuHYMNEZGRM3jkpm3bthg4cCAaNGiAK1euoFOnTgCACxcuwMfHp7DrIyoyf5+9g2GrT0vLM3r4o4yVwf9LEBFRCWPwyM2vv/6Kpk2b4v79+1i/fj0qVKgAAIiKikLPnj0LvUCiovDXmTv4dGU01Jon12va/2UrvO3vIXNVRERUGBRC39X4TFhKSgocHR2RnJwMBwcHucshGWg0Ao1/2IWktGwAvPIwEZExMOT7u0Bj8I8fP8bChQtx6dIlKBQK+Pn5YcCAAXB0dCxQwUTFJVetQYcZB6Rgc2JMG54VRURkYgw+LHXy5ElUrVoVP//8Mx4+fIikpCT8/PPPqFq1Kk6dOlUUNRIVCrVG4OuN53HtXhoA4G1/dwYbIiITZPBhqebNm6NatWqYP38+LCyeDPyoVCoMHDgQN27cwP79+4uk0MLCw1KlU7ZKjc9WRuOfi3cBALXdHbBlaHOZqyIiovwy5Pvb4HBjY2OD6Oho1KxZU6v94sWLCAwMREZGhuEVFyOGm9InR6WB79fbAADmZgqMe6sW3m/iDYVCIXNlRESUX4Z8fxt8WMrBwQFxcXE67fHx8bC3tzd0c0RFLuTnfdLzbzr5oU9THwYbIiITZnC46d69OwYMGIA1a9YgPj4et27dwurVqzFw4ECeCk4lzs2kdNx88GQ0sWNdV/RrVlnmioiIqKgZfLbUlClToFAo0LdvX6hUKgCApaUlPvnkE0yaNKnQCyQqqLspWVpXH57dO0C+YoiIqNgU+Do3GRkZuH79OoQQqFatGsqUMY7rhHDOTelw+FoShqw8hUcZuQCACW/XRp+mPvIWRUREBVYkc24yMjIwZMgQeHh4oGLFihg4cCDc3NxQr149owk2VHq8v/AYHmXkwqu8DRb0DWSwISIqRfIdbsaOHYslS5agU6dO6NGjByIjI/HJJ58UZW1EBfJvYir+/64KWNyvEdrUcpG3ICIiKlb5nnOzYcMGLFy4ED169AAAvP/++2jWrBnUajXMzXkXZSoZwv84jQ2nbkvLVZ3tZKyGiIjkkO+Rm/j4eDRv/t9Fzxo3bgwLCwvcuXOnSAojMlRSWrZWsBnepjpP+SYiKoXyPXKjVqthZWWlvbKFhXTGFJHcPl4eJT2/NrEDLMwNvtIBERGZgHyHGyEE+vXrB6Xyv3vxZGVlISwsDLa2tlLbhg0bCrdCopfIVWsQ/scZRMU+AvBkxIbBhoio9Mp3uPnggw902t5///1CLYbIUFm5anSccQA3ktKltg9f44X6iIhKs3yHm8WLFxdlHUQG02gEan6zXVr+sFllfPOmH+fZEBGVcrKP3c+ePRuVK1eGtbU1AgICcODAgXytd+jQIVhYWMDf379oC6QS6dajDFT5aqu0/HlbX3z7Vi0GGyIikjfcrFmzBsOHD8eYMWMQHR2N5s2bo0OHDnpvzPm05ORk9O3bF2+88UYxVUolybDV0Xjtxz3SchUnW3z2RnUZKyIiopKkwLdfKAxBQUFo2LAh5syZI7X5+fmhS5cuiIiIeO56PXr0QPXq1WFubo5Nmzbh9OnT+X5P3n7BuCUmZ6FJxC5pmbdVICIqHYrk9guFLScnB1FRUQgJCdFqDwkJweHDh5+73uLFi3H9+nWMHTu2qEukEiYhOVMr2Bz76g0GGyIi0mHwXcELS1JSEtRqNVxctC+N7+LigsTERL3rXL16FaNGjcKBAwdgYZG/0rOzs5GdnS0tp6SkFLxokk2OSoPgSbul5Xl9AuDiYC1jRUREVFIVaORm+fLlaNasGdzd3REbGwsAmD59Ov7880+Dt/XsBFAhhN5JoWq1Gr169cL48ePh6+ub7+1HRETA0dFRenh5eRlcI8krOTMXvl9vQ94B1K4NPRFS21XeooiIqMQyONzMmTMH4eHh6NixIx4/fgy1Wg0AKFu2LKZPn57v7Tg5OcHc3FxnlObevXs6ozkAkJqaipMnT+LTTz+FhYUFLCws8N133+HMmTOwsLDA7t27ddYBgNGjRyM5OVl6xMfH5//Dkuw0GoH64/+Rlns08sLU9+rLWBEREZV0BoebWbNmYf78+RgzZozWDTMDAwNx7ty5fG/HysoKAQEBiIyM1GqPjIxEcHCwTn8HBwecO3cOp0+flh5hYWGoUaMGTp8+jaCgIL3vo1Qq4eDgoPUg4yCE0Drde2jrapjUtZ6MFRERkTEweM5NTEwMGjRooNOuVCqRnp6uZ43nCw8PR58+fRAYGIimTZti3rx5iIuLQ1hYGIAnoy63b9/GsmXLYGZmhjp16mitX7FiRVhbW+u0k2noMvu/ieX1PB0xom3+D0cSEVHpZXC4qVy5Mk6fPg1vb2+t9m3btqFWrVoGbat79+548OABvvvuOyQkJKBOnTrYunWrtO2EhISXXvOGTI8QAj/vvIoz8Y8BAFWcbbH509fkLYqIiIyGwde5Wbx4Mb755htMnToVAwYMwIIFC3D9+nVERERgwYIF6NGjR1HVWih4nZuSLSUrF/XG/aPVFhPRkVceJiIq5Qz5/jZ45KZ///5QqVQYOXIkMjIy0KtXL3h4eGDGjBklPthQydd7/jHpubWlGY6PacNgQ0REBnmlKxQnJSVBo9GgYsWKhVlTkeLITck1c9dVTIu8AgBoXLk8/vi4qcwVERFRSVGkIzdPc3JyepXViSRbzyVIwQYAlvZvLGM1RERkzAo0ofhFhwlu3LjxSgVR6XPwahIGrzglLR8Y2Qo2VuYvWIOIiOj5DA43w4cP11rOzc1FdHQ0tm/fji+//LKw6qJSQqXW4P2F/82ziRzxOrzKl5GxIiIiMnYGh5thw4bpbf/1119x8uTJVy6ISo9ctQbVx2yTln8IrYvqLvYyVkRERKag0O4K3qFDB6xfv76wNkelQMvJe6Xn4W190SuoknzFEBGRySi0cLNu3TqUL1++sDZHJu5mUjpuP86Uloe+UV3GaoiIyJQYfFiqQYMGWhOKhRBITEzE/fv3MXv27EItjkyTEAItp+yVls+OC5GvGCIiMjkGh5suXbpoLZuZmcHZ2RktW7ZEzZo1C6suMlHJGbmo/91/VyCe0KUOHKwtZayIiIhMjUHhRqVSwcfHB+3atYOrq2tR1UQm6tlgAwC9G3OeDRERFS6D5txYWFjgk08+QXZ2dlHVQybsrV8OSs8HNa+Mm5M6wcyMt1YgIqLCZfCE4qCgIERHRxdFLWTCouMeIe5hBgCgc313jOlk2B3kiYiI8svgOTeDBw/G559/jlu3biEgIAC2trZar9erV6/QiiPTkJCcidDZh6XlmT0byFgNERGZunyHmw8//BDTp09H9+7dAQBDhw6VXlMoFBBCQKFQQK1WF36VZNS+2XReev5OAw8ZKyEiotIg33cFNzc3R0JCAjIzM1/Yz9vbu1AKKyq8K3jxin+YgTem7UOOSsM7fRMRUYEVyV3B8zJQSQ8vVHJM/edfzNp9TVqe07uhjNUQEVFpYdCE4hfdDZzoaZcSUrSCze8DglDBTiljRUREVFoYNKHY19f3pQHn4cOHr1QQGb8tZxMwZOUpaXnvFy3h42T7gjWIiIgKj0HhZvz48XB0dCyqWsjIZeaoMW7zBaw5GS+1ze7dkMGGiIiKlUHhpkePHqhYsWJR1UJGLuz3KOy7cl9aXvphY7TwdZaxIiIiKo3yHW4434Ze5HjMQynYVHW2xZqPm8KJc2yIiEgGBp8tRaTP4kMx0vPIES14WwUiIpJNvsONRqMpyjrIyN188OTWCq1rVmSwISIiWRl8bymiZ33/90VcSkgBALwb4ClzNUREVNoZfG8poqd9tfEcVh6Lk5bb1XaVsRoiIiKO3NAruPUoQyvYXJ7QHuY8JEVERDJjuKEC6/7bUen5kdGtYW1pLmM1RERETzDcUIHEP8zA7cdPbqLaLcATbo42MldERET0BMMNGSwzR43mP+2RlieG1pWxGiIiIm0MN2SQO48z4fftdmm5U103WFnw14iIiEoOni1F+dZy8h7pejZ5funVQKZqiIiI9OM/uSlfdl26qxVsBjWvjJuTOvG2HEREVOJw5IZeavXxOIzacE5a3vxpM9TzLCtfQURERC/AkRt6oVy1RivYTO1Wn8GGiIhKNIYbeqFpkVek5z92rYuuvL0CERGVcDwsRXr9m5iK9xcew/3UbABAeVsrdG9USeaqiIiIXo7hhnRExT5C1zmHpWVLcwWW9G8kY0VERET5x3BDWpIzcrWCzagONfFR8yow4z2jiIjISDDckJY+i45Jz3/rE8C7fBMRkdHhhGKSxD3IwNlbyQCAIa2qMtgQEZFRYrghAMD+K/fx+uT/7hc1vI2vjNUQEREVHA9LEX7afhmz916Xlqe9Vx+W5sy9RERknBhuSjkhhFaw2T68OWq6OshYERER0avhP89LsWyVGl1+PSQtM9gQEZEpYLgpxd5fcAxn/n8CcaXyZRhsiIjIJDDclFJLD9/EiZuPpOUdw1+XsRoiIqLCw3BTSo3dfEF6fnT0G7CxMpexGiIiosLDcFMKLT8aKz3/pVcDuDpay1gNERFR4WK4KWVy1Rp8s+m8tPxmPXcZqyEiIip8DDelSFauGtXHbJOWT4xpI2M1RERERYPhphQZuPSk9LxDHVc42ytlrIaIiKhoMNyUEtkqNQ5eSwIAONsrMef9AJkrIiIiKhoMN6XEkBWnpOdHRrWWsRIiIqKixXBTCoQtj8LOS/cAAJbmCljwvlFERGTC+C1n4radS8D2C4nS8vGvOImYiIhMm+zhZvbs2ahcuTKsra0REBCAAwcOPLfvhg0b0LZtWzg7O8PBwQFNmzbFjh07irFa45KtUuOTpw5H7QxvgXK2VjJWREREVPRkDTdr1qzB8OHDMWbMGERHR6N58+bo0KED4uLi9Pbfv38/2rZti61btyIqKgqtWrXCW2+9hejo6GKu3Dj8uvua9PynrvVQraKdjNUQEREVD4UQQsj15kFBQWjYsCHmzJkjtfn5+aFLly6IiIjI1zZq166N7t2749tvv81X/5SUFDg6OiI5ORkODqZ7o8iMHBVqffvfqNbNSZ1krIaIiOjVGPL9LdvITU5ODqKiohASEqLVHhISgsOHD+drGxqNBqmpqShfvnxRlGi0EpIztYLNn0OayVgNERFR8bKQ642TkpKgVqvh4uKi1e7i4oLExMTnrKVt6tSpSE9Px3vvvffcPtnZ2cjOzpaWU1JSClawEWkasVt63qORF+p7lZWvGCIiomIm+4RihUKhtSyE0GnTZ9WqVRg3bhzWrFmDihUrPrdfREQEHB0dpYeXl9cr11yS/bT9svS8RyMvTOpaT8ZqiIiIip9s4cbJyQnm5uY6ozT37t3TGc151po1azBgwAD88ccfaNPmxac2jx49GsnJydIjPj7+lWsvqbafT8Dsvdel5Yh36spYDRERkTxkCzdWVlYICAhAZGSkVntkZCSCg4Ofu96qVavQr18/rFy5Ep06vXySrFKphIODg9bDFKnUGoT9/t9p339/9lq+RsCIiIhMjWxzbgAgPDwcffr0QWBgIJo2bYp58+YhLi4OYWFhAJ6Muty+fRvLli0D8CTY9O3bFzNmzECTJk2kUR8bGxs4OjrK9jlKgnkHbkjPl/RvhDoepXt/EBFR6SVruOnevTsePHiA7777DgkJCahTpw62bt0Kb29vAEBCQoLWNW9+++03qFQqDBkyBEOGDJHaP/jgAyxZsqS4yy9Rftr+r/S8ZY3nz0EiIiIydbJe50YOpnidm/iHGWj+0x4AwPTu/ujSwEPmioiIiAqXUVznhgpP+B+npedv+7vLVwgREVEJwHBj5BYcuIETNx8BAMZ09OMkYiIiKvUYboxYZo4a32+5JC33aGza1/AhIiLKD4YbIzZr91Xp+V+fvgZ7a0sZqyEiIioZGG6M2OoTTy5I6GBtgbqePPWbiIgIYLgxWmfiH+Nheg4A4OtOtWSuhoiIqORguDFSb/96SHremWdIERERSRhujNA7s/8LNiPa+MLa0lzGaoiIiEoWhhsjo9YInIp7LC0Pa1NdvmKIiIhKIIYbI/P0Bfuiv2krXyFEREQlFMONkdl58S4AoKqzLcrZWslcDRERUcnDcGNEJu+4jPQcNQDgmzd5hhQREZE+DDdGYn3ULfy657q03MLXWcZqiIiISi6GGyNw8uZDfL72jLS8M7wF7yFFRET0HAw3JVzkxbt4d+4RaXnj4GBUq2gnY0VEREQlG8NNCTd6wznp+fIBjdGgUjkZqyEiIir5GG5KMCEEktKyAQDT3quP5tU5z4aIiOhlGG5KsJ2X7knP36jpImMlRERExoPhpoQSQmDQspMAAKWFGRzLWMpcERERkXFguCmBhBBoN32/tBzxTl0ZqyEiIjIuDDcl0IpjcbhyNw0A4O5ojXcaespcERERkfFguClhHmfk4OtN5wEATnZKHBrVWuaKiIiIjAvDTQnTdc5h6fmCDwJ5sT4iIiIDMdyUIClZubh+Px0AEFLLBf5eZeUtiIiIyAgx3JQQQggEfr9TWp7W3V++YoiIiIwYw00J8cXas8hRaQAAvYMqwU5pIXNFRERExonhpgSIf5iB9aduScufh9SQsRoiIiLjxnBTAoz/64L0/J8Rr6O8rZWM1RARERk3hhuZqTVCus1C5/ru8HWxl7kiIiIi48ZwI7Pvnhq1+bIdD0cRERG9KoYbmS09EgsAMDdTwKt8GZmrISIiMn4MNzIat/m/UZvfBwTJWAkREZHpYLiRiUqtwZLDNwEAFe2VaFq1grwFERERmQiGG5mE/PzfXb9/6xMgYyVERESmheFGBrsu3cWNpCe3WajqbIsGlcrJXBEREZHpYLiRwYClJ6XnW4Y2l7ESIiIi08NwU8xy1RrpeRd/d1hbmstYDRERkelhuClm7845LD0f37mOjJUQERGZJoabYpSckYszt5IBPDlDyrGMpcwVERERmR6Gm2LUceYB6fm+L1vJWAkREZHpYrgpJoevJeH240wAQLcAT9hYca4NERFRUWC4KQa5ag16LTgGALAwU2Byt/oyV0RERGS6GG6KwbTIK9Lzke15c0wiIqKixHBTDJb//80xAeCj16vKWAkREZHpY7gpYjN2XkVatgoAsLh/I5mrISIiMn0MN0Xs553/HZJq6essYyVERESlA8NNEVp1PE56vqhfIBQKhYzVEBERlQ4MN0UkV63B6A3npOVWNSrKWA0REVHpwXBTRFafiJeeT+/uz1EbIiKiYsJwU0SWHb4pPe/SwEO+QoiIiEoZhpsikJWrxtV7aQCAQc0ry1wNERFR6cJwUwSGrDglPQ9rwevaEBERFSeGm0KWo9Jg1+V7AACfCmVQwU4pc0VERESlC8NNITt/J1l6vmFwMxkrISIiKp0YbgrZsRsPAQB2SguUt7WSuRoiIqLSh+GmkP24/TIAoLa7g8yVEBERlU4MN4Xo8PUk6XmLGrzVAhERkRxkDzezZ89G5cqVYW1tjYCAABw4cOCF/fft24eAgABYW1ujSpUqmDt3bjFV+nI7zidKzz/hWVJERESykDXcrFmzBsOHD8eYMWMQHR2N5s2bo0OHDoiLi9PbPyYmBh07dkTz5s0RHR2Nr776CkOHDsX69euLuXL98q5C3NinPK9ITEREJBOFEELI9eZBQUFo2LAh5syZI7X5+fmhS5cuiIiI0On/v//9D5s3b8alS5ektrCwMJw5cwZHjhzJ13umpKTA0dERycnJcHAo3HkxPqO2AAC+bFcDQ1pVK9RtExERlWaGfH/LNnKTk5ODqKgohISEaLWHhITg8OHDetc5cuSITv927drh5MmTyM3N1btOdnY2UlJStB5FISNHJT33qWBbJO9BRERELydbuElKSoJarYaLi4tWu4uLCxITE/Wuk5iYqLe/SqVCUlKS3nUiIiLg6OgoPby8vArnAzwj/mEm3B2tAQAd67oWyXsQERHRy8k+ofjZuSlCiBfOV9HXX197ntGjRyM5OVl6xMfH6+33qmq42uPQqNY49U1bzrchIiKSkYVcb+zk5ARzc3OdUZp79+7pjM7kcXV11dvfwsICFSpU0LuOUqmEUlk8t0BQKBS8cB8REZHMZBu5sbKyQkBAACIjI7XaIyMjERwcrHedpk2b6vT/559/EBgYCEtLyyKrlYiIiIyHrIelwsPDsWDBAixatAiXLl3CiBEjEBcXh7CwMABPDin17dtX6h8WFobY2FiEh4fj0qVLWLRoERYuXIgvvvhCro9AREREJYxsh6UAoHv37njw4AG+++47JCQkoE6dOti6dSu8vb0BAAkJCVrXvKlcuTK2bt2KESNG4Ndff4W7uztmzpyJrl27yvURiIiIqISR9To3cijK69wQERFR0TCK69wQERERFQWGGyIiIjIpDDdERERkUhhuiIiIyKQw3BAREZFJYbghIiIik8JwQ0RERCaF4YaIiIhMCsMNERERmRRZb78gh7wLMqekpMhcCREREeVX3vd2fm6sUOrCTWpqKgDAy8tL5kqIiIjIUKmpqXB0dHxhn1J3bymNRoM7d+7A3t4eCoWiULedkpICLy8vxMfH875VRYj7uXhwPxcP7ufiw31dPIpqPwshkJqaCnd3d5iZvXhWTakbuTEzM4Onp2eRvoeDgwP/xykG3M/Fg/u5eHA/Fx/u6+JRFPv5ZSM2eTihmIiIiEwKww0RERGZFIabQqRUKjF27FgolUq5SzFp3M/Fg/u5eHA/Fx/u6+JREvZzqZtQTERERKaNIzdERERkUhhuiIiIyKQw3BAREZFJYbghIiIik8JwY6DZs2ejcuXKsLa2RkBAAA4cOPDC/vv27UNAQACsra1RpUoVzJ07t5gqNW6G7OcNGzagbdu2cHZ2hoODA5o2bYodO3YUY7XGy9Df5zyHDh2ChYUF/P39i7ZAE2Hofs7OzsaYMWPg7e0NpVKJqlWrYtGiRcVUrfEydD+vWLEC9evXR5kyZeDm5ob+/fvjwYMHxVStcdq/fz/eeustuLu7Q6FQYNOmTS9dR5bvQUH5tnr1amFpaSnmz58vLl68KIYNGyZsbW1FbGys3v43btwQZcqUEcOGDRMXL14U8+fPF5aWlmLdunXFXLlxMXQ/Dxs2TPz444/i+PHj4sqVK2L06NHC0tJSnDp1qpgrNy6G7uc8jx8/FlWqVBEhISGifv36xVOsESvIfu7cubMICgoSkZGRIiYmRhw7dkwcOnSoGKs2Pobu5wMHDggzMzMxY8YMcePGDXHgwAFRu3Zt0aVLl2Ku3Lhs3bpVjBkzRqxfv14AEBs3bnxhf7m+BxluDNC4cWMRFham1VazZk0xatQovf1HjhwpatasqdX28ccfiyZNmhRZjabA0P2sT61atcT48eMLuzSTUtD93L17d/H111+LsWPHMtzkg6H7edu2bcLR0VE8ePCgOMozGYbu58mTJ4sqVapotc2cOVN4enoWWY2mJj/hRq7vQR6WyqecnBxERUUhJCREqz0kJASHDx/Wu86RI0d0+rdr1w4nT55Ebm5ukdVqzAqyn5+l0WiQmpqK8uXLF0WJJqGg+3nx4sW4fv06xo4dW9QlmoSC7OfNmzcjMDAQP/30Ezw8PODr64svvvgCmZmZxVGyUSrIfg4ODsatW7ewdetWCCFw9+5drFu3Dp06dSqOkksNub4HS92NMwsqKSkJarUaLi4uWu0uLi5ITEzUu05iYqLe/iqVCklJSXBzcyuyeo1VQfbzs6ZOnYr09HS89957RVGiSSjIfr569SpGjRqFAwcOwMKCfzryoyD7+caNGzh48CCsra2xceNGJCUlYfDgwXj48CHn3TxHQfZzcHAwVqxYge7duyMrKwsqlQqdO3fGrFmziqPkUkOu70GO3BhIoVBoLQshdNpe1l9fO2kzdD/nWbVqFcaNG4c1a9agYsWKRVWeycjvflar1ejVqxfGjx8PX1/f4irPZBjy+6zRaKBQKLBixQo0btwYHTt2xLRp07BkyRKO3ryEIfv54sWLGDp0KL799ltERUVh+/btiImJQVhYWHGUWqrI8T3If37lk5OTE8zNzXX+FXDv3j2dVJrH1dVVb38LCwtUqFChyGo1ZgXZz3nWrFmDAQMGYO3atWjTpk1Rlmn0DN3PqampOHnyJKKjo/Hpp58CePIlLISAhYUF/vnnH7Ru3bpYajcmBfl9dnNzg4eHBxwdHaU2Pz8/CCFw69YtVK9evUhrNkYF2c8RERFo1qwZvvzySwBAvXr1YGtri+bNm+P777/nyHohket7kCM3+WRlZYWAgABERkZqtUdGRiI4OFjvOk2bNtXp/88//yAwMBCWlpZFVqsxK8h+Bp6M2PTr1w8rV67kMfN8MHQ/Ozg44Ny5czh9+rT0CAsLQ40aNXD69GkEBQUVV+lGpSC/z82aNcOdO3eQlpYmtV25cgVmZmbw9PQs0nqNVUH2c0ZGBszMtL8Czc3NAfw3skCvTrbvwSKdrmxi8k41XLhwobh48aIYPny4sLW1FTdv3hRCCDFq1CjRp08fqX/eKXAjRowQFy9eFAsXLuSp4Plg6H5euXKlsLCwEL/++qtISEiQHo8fP5brIxgFQ/fzs3i2VP4Yup9TU1OFp6enePfdd8WFCxfEvn37RPXq1cXAgQPl+ghGwdD9vHjxYmFhYSFmz54trl+/Lg4ePCgCAwNF48aN5foIRiE1NVVER0eL6OhoAUBMmzZNREdHS6fcl5TvQYYbA/3666/C29tbWFlZiYYNG4p9+/ZJr33wwQeiRYsWWv337t0rGjRoIKysrISPj4+YM2dOMVdsnAzZzy1atBAAdB4ffPBB8RduZAz9fX4aw03+GbqfL126JNq0aSNsbGyEp6enCA8PFxkZGcVctfExdD/PnDlT1KpVS9jY2Ag3NzfRu3dvcevWrWKu2rjs2bPnhX9vS8r3oEIIjr8RERGR6eCcGyIiIjIpDDdERERkUhhuiIiIyKQw3BAREZFJYbghIiIik8JwQ0RERCaF4YaIiIhMCsMNEWlZsmQJypYtK3cZBebj44Pp06e/sM+4cePg7+9fLPUQUfFjuCEyQf369YNCodB5XLt2Te7SsGTJEq2a3Nzc8N577yEmJqZQtn/ixAl89NFH0rJCocCmTZu0+nzxxRfYtWtXobzf8zz7OV1cXPDWW2/hwoULBm/HmMMmkRwYbohMVPv27ZGQkKD1qFy5stxlAXhyI86EhATcuXMHK1euxOnTp9G5c2eo1epX3razszPKlCnzwj52dnZFekfiPE9/zi1btiA9PR2dOnVCTk5Okb83UWnGcENkopRKJVxdXbUe5ubmmDZtGurWrQtbW1t4eXlh8ODBWnegftaZM2fQqlUr2Nvbw8HBAQEBATh58qT0+uHDh/H666/DxsYGXl5eGDp0KNLT019Ym0KhgKurK9zc3NCqVSuMHTsW58+fl0aW5syZg6pVq8LKygo1atTA8uXLtdYfN24cKlWqBKVSCXd3dwwdOlR67enDUj4+PgCA0NBQKBQKafnpw1I7duyAtbU1Hj9+rPUeQ4cORYsWLQrtcwYGBmLEiBGIjY3Fv//+K/V50c9j79696N+/P5KTk6URoHHjxgEAcnJyMHLkSHh4eMDW1hZBQUHYu3fvC+shKi0YbohKGTMzM8ycORPnz5/H0qVLsXv3bowcOfK5/Xv37g1PT0+cOHECUVFRGDVqFCwtLQEA586dQ7t27fDOO+/g7NmzWLNmDQ4ePIhPP/3UoJpsbGwAALm5udi4cSOGDRuGzz//HOfPn8fHH3+M/v37Y8+ePQCAdevW4eeff8Zvv/2Gq1evYtOmTahbt67e7Z44cQIAsHjxYiQkJEjLT2vTpg3Kli2L9evXS21qtRp//PEHevfuXWif8/Hjx1i5ciUASPsPePHPIzg4GNOnT5dGgBISEvDFF18AAPr3749Dhw5h9erVOHv2LLp164b27dvj6tWr+a6JyGQV+a05iajYffDBB8Lc3FzY2tpKj3fffVdv3z/++ENUqFBBWl68eLFwdHSUlu3t7cWSJUv0rtunTx/x0UcfabUdOHBAmJmZiczMTL3rPLv9+Ph40aRJE+Hp6Smys7NFcHCwGDRokNY63bp1Ex07dhRCCDF16lTh6+srcnJy9G7f29tb/Pzzz9IyALFx40atPs/e0Xzo0KGidevW0vKOHTuElZWVePjw4St9TgDC1tZWlClTRrp7cufOnfX2z/Oyn4cQQly7dk0oFApx+/ZtrfY33nhDjB49+oXbJyoNLOSNVkRUVFq1aoU5c+ZIy7a2tgCAPXv24IcffsDFixeRkpIClUqFrKwspKenS32eFh4ejoEDB2L58uVo06YNunXrhqpVqwIAoqKicO3aNaxYsULqL4SARqNBTEwM/Pz89NaWnJwMOzs7CCGQkZGBhg0bYsOGDbCyssKlS5e0JgQDQLNmzTBjxgwAQLdu3TB9+nRUqVIF7du3R8eOHfHWW2/BwqLgf8569+6Npk2b4s6dO3B3d8eKFSvQsWNHlCtX7pU+p729PU6dOgWVSoV9+/Zh8uTJmDt3rlYfQ38eAHDq1CkIIeDr66vVnp2dXSxziYhKOoYbIhNla2uLatWqabXFxsaiY8eOCAsLw4QJE1C+fHkcPHgQAwYMQG5urt7tjBs3Dr169cKWLVuwbds2jB07FqtXr0ZoaCg0Gg0+/vhjrTkveSpVqvTc2vK+9M3MzODi4qLzJa5QKLSWhRBSm5eXF/79919ERkZi586dGDx4MCZPnox9+/ZpHe4xROPGjVG1alWsXr0an3zyCTZu3IjFixdLrxf0c5qZmUk/g5o1ayIxMRHdu3fH/v37ARTs55FXj7m5OaKiomBubq71mp2dnUGfncgUMdwQlSInT56ESqXC1KlTYWb2ZMrdH3/88dL1fH194evrixEjRqBnz55YvHgxQkND0bBhQ1y4cEEnRL3M01/6z/Lz88PBgwfRt29fqe3w4cNaoyM2Njbo3LkzOnfujCFDhqBmzZo4d+4cGjZsqLM9S0vLfJ2F1atXL6xYsQKenp4wMzNDp06dpNcK+jmfNWLECEybNg0bN25EaGhovn4eVlZWOvU3aNAAarUa9+7dQ/PmzV+pJiJTxAnFRKVI1apVoVKpMGvWLNy4cQPLly/XOUzytMzMTHz66afYu3cvYmNjcejQIZw4cUIKGv/73/9w5MgRDBkyBKdPn8bVq1exefNmfPbZZwWu8csvv8SSJUswd+5cXL16FdOmTcOGDRukibRLlizBwoULcf78eekz2NjYwNvbW+/2fHx8sGvXLiQmJuLRo0fPfd/evXvj1KlTmDhxIt59911YW1tLrxXW53RwcMDAgQMxduxYCCHy9fPw8fFBWloadu3ahaSkJGRkZMDX1xe9e/dG3759sWHDBsTExODEiRP48ccfsXXrVoNqIjJJck74IaKi8cEHH4i3335b72vTpk0Tbm5uwsbGRrRr104sW7ZMABCPHj0SQmhPYM3OzhY9evQQXl5ewsrKSri7u4tPP/1UaxLt8ePHRdu2bYWdnZ2wtbUV9erVExMnTnxubfomyD5r9uzZokqVKsLS0lL4+vqKZcuWSa9t3LhRBAUFCQcHB2FrayuaNGkidu7cKb3+7ITizZs3i2rVqgkLCwvh7e0thNCdUJynUaNGAoDYvXu3zmuF9TljY2OFhYWFWLNmjRDi5T8PIYQICwsTFSpUEADE2LFjhRBC5OTkiG+//Vb4+PgIS0tL4erqKkJDQ8XZs2efWxNRaaEQQgh54xURERFR4eFhKSIiIjIpDDdERERkUhhuiIiIyKQw3BAREZFJYbghIiIik8JwQ0RERCaF4YaIiIhMCsMNERERmRSGGyIiIjIpDDdERERkUhhuiIiIyKQw3BAREZFJ+T9ln6f8JdIlvQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#init the model \n",
    "gb = GradientBoostingClassifier(random_state=42)\n",
    "doMLClassification(gb, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "ee5fdd6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#feature importances of ada model \n",
    "\n",
    "#sorted(list(zip(ada.feature_importances_, X.columns)), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "dff3a71d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.622893850042123\n"
     ]
    }
   ],
   "source": [
    "#calculate the accuracy score of the ada model way #1\n",
    "\n",
    "y_pred = gb.predict(X_test)\n",
    "print(gb.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "68f7181e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.622893850042123"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#way #2 to calculate the accuracy score\n",
    "\n",
    "accuracy_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "0a38d5ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1, 1, 1, ..., 0, 1, 1], dtype=int64),\n",
       " 20106    0\n",
       " 5564     0\n",
       " 5266     1\n",
       " 31254    1\n",
       " 1428     0\n",
       "         ..\n",
       " 16509    1\n",
       " 27837    1\n",
       " 35264    0\n",
       " 6449     0\n",
       " 39828    0\n",
       " Name: disposition, Length: 9496, dtype: int64)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "664d74e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#max_features: number of features that will use to construct the model \n",
    "#n estimators = trees that we will use to construct the prediction model \n",
    "#search for optimal parameters (gridsearch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "9719b77f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:  {'learning_rate': 0.01, 'n_estimators': 50}\n",
      "Best Score:  0.4764729541065599\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Create an instance of AdaBoostClassifier\n",
    "gb = GradientBoostingClassifier(random_state=42)\n",
    "\n",
    "\n",
    "# Define the hyperparameters and their range\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [0.01, 0.1, 1]\n",
    "}\n",
    "\n",
    "# Create a GridSearchCV object\n",
    "grid_search = GridSearchCV(gb, param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# Fit the GridSearchCV object to the data\n",
    "grid_result = grid_search.fit(X, y)\n",
    "\n",
    "# Print the best parameters and the corresponding score\n",
    "print(\"Best Parameters: \", grid_result.best_params_)\n",
    "print(\"Best Score: \", grid_result.best_score_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3cc7d93",
   "metadata": {},
   "source": [
    "Hyper Parameter Tuning using GridSearch CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "72b2419b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"â¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â¾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=GradientBoostingClassifier(random_state=42),\n",
       "             param_grid={&#x27;max_features&#x27;: [&#x27;auto&#x27;, &#x27;sqrt&#x27;, &#x27;log2&#x27;, None, 0.2,\n",
       "                                          0.5, 0.8],\n",
       "                         &#x27;n_estimators&#x27;: array([ 10,  20,  30,  40,  50,  60,  70,  80,  90, 100, 110, 120, 130,\n",
       "       140, 150, 160, 170, 180, 190, 200, 210])},\n",
       "             scoring=&#x27;accuracy&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=GradientBoostingClassifier(random_state=42),\n",
       "             param_grid={&#x27;max_features&#x27;: [&#x27;auto&#x27;, &#x27;sqrt&#x27;, &#x27;log2&#x27;, None, 0.2,\n",
       "                                          0.5, 0.8],\n",
       "                         &#x27;n_estimators&#x27;: array([ 10,  20,  30,  40,  50,  60,  70,  80,  90, 100, 110, 120, 130,\n",
       "       140, 150, 160, 170, 180, 190, 200, 210])},\n",
       "             scoring=&#x27;accuracy&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier(random_state=42)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier(random_state=42)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=GradientBoostingClassifier(random_state=42),\n",
       "             param_grid={'max_features': ['auto', 'sqrt', 'log2', None, 0.2,\n",
       "                                          0.5, 0.8],\n",
       "                         'n_estimators': array([ 10,  20,  30,  40,  50,  60,  70,  80,  90, 100, 110, 120, 130,\n",
       "       140, 150, 160, 170, 180, 190, 200, 210])},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "max_features_range = ['auto', 'sqrt', 'log2', None, 0.2, 0.5, 0.8]\n",
    "n_estimators_range = np.arange(10, 220, 10)\n",
    "\n",
    "param_grid = {\n",
    "    'max_features': max_features_range,\n",
    "    'n_estimators': n_estimators_range\n",
    "}\n",
    "\n",
    "gb= GradientBoostingClassifier(random_state = 42)\n",
    "\n",
    "grid = GridSearchCV(gb, param_grid, scoring = 'accuracy', cv=5)\n",
    "grid\n",
    "\n",
    "#Note: LGBM has feature fraction parameter, it is a hyperparameter that control the fraction of features to consider for each tree, \n",
    "# and it is typically between 0-1. This range allows us to try different fractions of features in our model. The array for \n",
    "#feature_fraction_range is [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]. LGBM does not have max_features like other tree \n",
    "#based models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "0815d19a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:  {'learning_rate': 0.01, 'n_estimators': 50}\n",
      "Best Score:  0.4764729541065599\n"
     ]
    }
   ],
   "source": [
    "grid_result = grid_search.fit(X, y)\n",
    "\n",
    "# Print the best parameters and the corresponding score\n",
    "print(\"Best Parameters: \", grid_result.best_params_)\n",
    "print(\"Best Score: \", grid_result.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "aeb02f66",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GridSearchCV' object has no attribute 'cv_results_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[128], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Extract the parameters and mean test scores\u001b[39;00m\n\u001b[0;32m      2\u001b[0m grid_results \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\n\u001b[1;32m----> 3\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_features\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[43mgrid\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcv_results_\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_features_range\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_estimators\u001b[39m\u001b[38;5;124m\"\u001b[39m: grid\u001b[38;5;241m.\u001b[39mcv_results_[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_estimators_range\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m: grid\u001b[38;5;241m.\u001b[39mcv_results_[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean_test_score\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m      6\u001b[0m })\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Rename columns\u001b[39;00m\n\u001b[0;32m      9\u001b[0m grid_results\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_features\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_estimators\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'GridSearchCV' object has no attribute 'cv_results_'"
     ]
    }
   ],
   "source": [
    "\n",
    "# Extract the parameters and mean test scores\n",
    "grid_results = pd.DataFrame({\n",
    "    \"max_features\": grid.cv_results_[\"max_features_range\"],\n",
    "    \"n_estimators\": grid.cv_results_[\"n_estimators_range\"],\n",
    "    \"Accuracy\": grid.cv_results_[\"mean_test_score\"]\n",
    "})\n",
    "\n",
    "# Rename columns\n",
    "grid_results.columns = [\"max_features\", \"n_estimators\", \"Accuracy\"]\n",
    "\n",
    "# Display the results\n",
    "print(grid_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578cf721",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba0f3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_contour = grid_results.groupby([\"max_features\", \"n_estimators\"]).mean()\n",
    "grid_contour\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0d32cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data is reshaped by pivoting the data into an m by n matrix where rows and columns correspond to the \"feature_fractions\" and \"n_estimators\"\n",
    "\n",
    "grid_reset = grid_contour.reset_index()\n",
    "grid_reset.columns = ['feature_fraction', 'n_estimators', 'Accuracy']\n",
    "grid_pivot = grid_reset.pivot(\"feature_fraction\", 'n_estimators', 'Accuracy')\n",
    "grid_pivot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bfb92db",
   "metadata": {},
   "outputs": [],
   "source": [
    "##assign the pivot table above to x, y and z variables \n",
    "x = grid_pivot.columns.to_numpy()\n",
    "y = grid_pivot.index.to_numpy()\n",
    "z = grid_pivot.to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8900a592",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "layout = go.Layout(\n",
    "            xaxis = go.layout.XAxis(\n",
    "                title = go.layout.xaxis.Title(\n",
    "                text = \"max_features\")\n",
    "            ), \n",
    "            yaxis = go.layout.YAxis(\n",
    "                title = go.layout.yaxis.Title(\n",
    "            text = \"n_estimators\")\n",
    "            ))\n",
    "fig = go.Figure(data = [go.Contour(z = z, x =x, y =y)], layout = layout)\n",
    "fig.update_layout(title=\"Hyperparameter tuning\", autosize=False, width=500, height=500, margin=dict(l=65, r=50, b=65, t=90))\n",
    "\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b762b614",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3D Surface Plot \n",
    "\n",
    "fig = go.Figure(data = [go.Surface(z = z , y = y, x = x )], layout = layout)\n",
    "fig.update_layout (title = \"Hyperparameter tuning\", \n",
    "                  scene = dict(\n",
    "                  xaxis_title = 'feature_fraction', \n",
    "                  yaxis_title = 'max_features', \n",
    "                  zaxis_title = \"Accuracy\"), \n",
    "                  autosize = False, \n",
    "                  width = 1000, height = 1000, \n",
    "                  margin = dict (l = 65, r = 50, b = 65, t = 90))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991871a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ead410",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "\n",
    "# Initialize AdaBoostClassifier with a large number of estimators\n",
    "ada = AdaBoostClassifier(n_estimators=300, random_state=42)\n",
    "\n",
    "# Train the model on the training data\n",
    "ada.fit(X_train, y_train)\n",
    "\n",
    "# Monitor performance on the validation set\n",
    "val_predictions = ada.predict(X_test)\n",
    "val_accuracy = accuracy_score(y_test, val_predictions)\n",
    "\n",
    "# Initialize variables for early stopping\n",
    "best_val_accuracy = val_accuracy\n",
    "best_estimators = 300\n",
    "tolerance = 10  # Number of consecutive iterations with no improvement to tolerate\n",
    "\n",
    "for i in range(300):\n",
    "    # Train for one more iteration\n",
    "    ada.n_estimators += 1\n",
    "    ada.fit(X_train, y_train)\n",
    "    \n",
    "    # Monitor performance on the validation set\n",
    "    val_predictions = ada.predict(X_test)\n",
    "    val_accuracy = accuracy_score(y_test, val_predictions)\n",
    "    \n",
    "    if val_accuracy > best_val_accuracy:\n",
    "        best_val_accuracy = val_accuracy\n",
    "        best_estimators = ada.n_estimators\n",
    "        tolerance = 10  # Reset tolerance if there's improvement\n",
    "    else:\n",
    "        tolerance -= 1\n",
    "    \n",
    "    if tolerance == 0:\n",
    "        break\n",
    "\n",
    "# Use the best number of estimators\n",
    "ada.n_estimators = best_estimators\n",
    "\n",
    "# Final training\n",
    "ada.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "test_predictions = ada.predict(X_test)\n",
    "test_accuracy = accuracy_score(y_test, test_predictions)\n",
    "\n",
    "print(f\"Best Number of Estimators: {best_estimators}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4297e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "id": "00abbd24",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = make_pipeline(CountVectorizer(), MultinomialNB())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "id": "d4f59676",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 18576, number of negative: 19406\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004124 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 563\n",
      "[LightGBM] [Info] Number of data points in the train set: 37982, number of used features: 107\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.489074 -> initscore=-0.043712\n",
      "[LightGBM] [Info] Start training from score -0.043712\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6252106149957877"
      ]
     },
     "execution_count": 522,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm.fit(X_train, y_train)\n",
    "test_data_prediction = lgbm.predict(X_test)\n",
    "accuracy = accuracy_score (y_test, test_data_prediction)\n",
    "accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "id": "35a089a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cross validation test  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "id": "e1a71eab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>victim_age</th>\n",
       "      <th>reported_year</th>\n",
       "      <th>POPULATION</th>\n",
       "      <th>victim_sex_Female</th>\n",
       "      <th>victim_sex_Male</th>\n",
       "      <th>victim_race_Asian</th>\n",
       "      <th>victim_race_Black</th>\n",
       "      <th>victim_race_Hispanic</th>\n",
       "      <th>victim_race_Other</th>\n",
       "      <th>victim_race_White</th>\n",
       "      <th>...</th>\n",
       "      <th>state_NM</th>\n",
       "      <th>state_NV</th>\n",
       "      <th>state_NY</th>\n",
       "      <th>state_OH</th>\n",
       "      <th>state_OK</th>\n",
       "      <th>state_PA</th>\n",
       "      <th>state_TN</th>\n",
       "      <th>state_TX</th>\n",
       "      <th>state_VA</th>\n",
       "      <th>state_WI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>78</td>\n",
       "      <td>2010</td>\n",
       "      <td>545852</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17</td>\n",
       "      <td>2010</td>\n",
       "      <td>545852</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15</td>\n",
       "      <td>2010</td>\n",
       "      <td>545852</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32</td>\n",
       "      <td>2010</td>\n",
       "      <td>545852</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>72</td>\n",
       "      <td>2010</td>\n",
       "      <td>545852</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47473</th>\n",
       "      <td>29</td>\n",
       "      <td>2016</td>\n",
       "      <td>687576</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47474</th>\n",
       "      <td>19</td>\n",
       "      <td>2016</td>\n",
       "      <td>687576</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47475</th>\n",
       "      <td>23</td>\n",
       "      <td>2016</td>\n",
       "      <td>687576</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47476</th>\n",
       "      <td>24</td>\n",
       "      <td>2016</td>\n",
       "      <td>687576</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47477</th>\n",
       "      <td>17</td>\n",
       "      <td>2016</td>\n",
       "      <td>687576</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>47478 rows Ã 107 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       victim_age  reported_year  POPULATION  victim_sex_Female  \\\n",
       "0              78           2010      545852                  0   \n",
       "1              17           2010      545852                  0   \n",
       "2              15           2010      545852                  1   \n",
       "3              32           2010      545852                  0   \n",
       "4              72           2010      545852                  1   \n",
       "...           ...            ...         ...                ...   \n",
       "47473          29           2016      687576                  0   \n",
       "47474          19           2016      687576                  0   \n",
       "47475          23           2016      687576                  0   \n",
       "47476          24           2016      687576                  0   \n",
       "47477          17           2016      687576                  0   \n",
       "\n",
       "       victim_sex_Male  victim_race_Asian  victim_race_Black  \\\n",
       "0                    1                  0                  0   \n",
       "1                    1                  0                  0   \n",
       "2                    0                  0                  0   \n",
       "3                    1                  0                  0   \n",
       "4                    0                  0                  0   \n",
       "...                ...                ...                ...   \n",
       "47473                1                  0                  1   \n",
       "47474                1                  0                  1   \n",
       "47475                1                  0                  1   \n",
       "47476                1                  0                  1   \n",
       "47477                1                  0                  1   \n",
       "\n",
       "       victim_race_Hispanic  victim_race_Other  victim_race_White  ...  \\\n",
       "0                         1                  0                  0  ...   \n",
       "1                         1                  0                  0  ...   \n",
       "2                         0                  0                  1  ...   \n",
       "3                         1                  0                  0  ...   \n",
       "4                         0                  0                  1  ...   \n",
       "...                     ...                ...                ...  ...   \n",
       "47473                     0                  0                  0  ...   \n",
       "47474                     0                  0                  0  ...   \n",
       "47475                     0                  0                  0  ...   \n",
       "47476                     0                  0                  0  ...   \n",
       "47477                     0                  0                  0  ...   \n",
       "\n",
       "       state_NM  state_NV  state_NY  state_OH  state_OK  state_PA  state_TN  \\\n",
       "0             1         0         0         0         0         0         0   \n",
       "1             1         0         0         0         0         0         0   \n",
       "2             1         0         0         0         0         0         0   \n",
       "3             1         0         0         0         0         0         0   \n",
       "4             1         0         0         0         0         0         0   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "47473         0         0         0         0         0         0         0   \n",
       "47474         0         0         0         0         0         0         0   \n",
       "47475         0         0         0         0         0         0         0   \n",
       "47476         0         0         0         0         0         0         0   \n",
       "47477         0         0         0         0         0         0         0   \n",
       "\n",
       "       state_TX  state_VA  state_WI  \n",
       "0             0         0         0  \n",
       "1             0         0         0  \n",
       "2             0         0         0  \n",
       "3             0         0         0  \n",
       "4             0         0         0  \n",
       "...         ...       ...       ...  \n",
       "47473         0         0         0  \n",
       "47474         0         0         0  \n",
       "47475         0         0         0  \n",
       "47476         0         0         0  \n",
       "47477         0         0         0  \n",
       "\n",
       "[47478 rows x 107 columns]"
      ]
     },
     "execution_count": 524,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "id": "c43ae853",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. ])"
      ]
     },
     "execution_count": 525,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "id": "4cb88fa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 16718, number of negative: 17465\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002519 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 564\n",
      "[LightGBM] [Info] Number of data points in the train set: 34183, number of used features: 107\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.489074 -> initscore=-0.043713\n",
      "[LightGBM] [Info] Start training from score -0.043713\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 16718, number of negative: 17465\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002475 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 564\n",
      "[LightGBM] [Info] Number of data points in the train set: 34183, number of used features: 107\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.489074 -> initscore=-0.043713\n",
      "[LightGBM] [Info] Start training from score -0.043713\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 16718, number of negative: 17466\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002008 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 564\n",
      "[LightGBM] [Info] Number of data points in the train set: 34184, number of used features: 107\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.489059 -> initscore=-0.043770\n",
      "[LightGBM] [Info] Start training from score -0.043770\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 16718, number of negative: 17466\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002671 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 563\n",
      "[LightGBM] [Info] Number of data points in the train set: 34184, number of used features: 107\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.489059 -> initscore=-0.043770\n",
      "[LightGBM] [Info] Start training from score -0.043770\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 16718, number of negative: 17466\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001637 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 564\n",
      "[LightGBM] [Info] Number of data points in the train set: 34184, number of used features: 107\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.489059 -> initscore=-0.043770\n",
      "[LightGBM] [Info] Start training from score -0.043770\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 16718, number of negative: 17466\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001720 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 564\n",
      "[LightGBM] [Info] Number of data points in the train set: 34184, number of used features: 107\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.489059 -> initscore=-0.043770\n",
      "[LightGBM] [Info] Start training from score -0.043770\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 16719, number of negative: 17465\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002627 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 562\n",
      "[LightGBM] [Info] Number of data points in the train set: 34184, number of used features: 107\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.489088 -> initscore=-0.043653\n",
      "[LightGBM] [Info] Start training from score -0.043653\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 16719, number of negative: 17465\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001597 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 561\n",
      "[LightGBM] [Info] Number of data points in the train set: 34184, number of used features: 107\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.489088 -> initscore=-0.043653\n",
      "[LightGBM] [Info] Start training from score -0.043653\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 16719, number of negative: 17465\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004458 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 563\n",
      "[LightGBM] [Info] Number of data points in the train set: 34184, number of used features: 107\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.489088 -> initscore=-0.043653\n",
      "[LightGBM] [Info] Start training from score -0.043653\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 16719, number of negative: 17465\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003502 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 564\n",
      "[LightGBM] [Info] Number of data points in the train set: 34184, number of used features: 107\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.489088 -> initscore=-0.043653\n",
      "[LightGBM] [Info] Start training from score -0.043653\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-0.48004313, -0.45476126, -0.49622141, -0.51202657, -0.53099275,\n",
       "       -0.47304052, -0.5257595 , -0.48150405, -0.47096703, -0.51943729])"
      ]
     },
     "execution_count": 526,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# 10 fold cv\n",
    "scores = cross_val_score(lgbm, X_train, y_train, scoring='r2', cv=10)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "id": "712703c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.4944753514995047\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "id": "647d6d86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 3715, number of negative: 3881\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000800 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 557\n",
      "[LightGBM] [Info] Number of data points in the train set: 7596, number of used features: 107\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.489073 -> initscore=-0.043714\n",
      "[LightGBM] [Info] Start training from score -0.043714\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 3716, number of negative: 3881\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000428 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 551\n",
      "[LightGBM] [Info] Number of data points in the train set: 7597, number of used features: 107\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.489140 -> initscore=-0.043445\n",
      "[LightGBM] [Info] Start training from score -0.043445\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 3715, number of negative: 3882\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000239 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 556\n",
      "[LightGBM] [Info] Number of data points in the train set: 7597, number of used features: 107\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.489009 -> initscore=-0.043972\n",
      "[LightGBM] [Info] Start training from score -0.043972\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 3715, number of negative: 3882\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000684 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 551\n",
      "[LightGBM] [Info] Number of data points in the train set: 7597, number of used features: 107\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.489009 -> initscore=-0.043972\n",
      "[LightGBM] [Info] Start training from score -0.043972\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 3715, number of negative: 3882\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000442 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 554\n",
      "[LightGBM] [Info] Number of data points in the train set: 7597, number of used features: 107\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.489009 -> initscore=-0.043972\n",
      "[LightGBM] [Info] Start training from score -0.043972\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, ..., 0, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 528,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#printing the scores on test dataset \n",
    "# first : prediction \n",
    "from sklearn.model_selection import cross_val_predict \n",
    "pred = cross_val_predict(lgbm, X_test, y_test)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "id": "f7f21234",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 4180, number of negative: 4366\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000565 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 556\n",
      "[LightGBM] [Info] Number of data points in the train set: 8546, number of used features: 107\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.489118 -> initscore=-0.043536\n",
      "[LightGBM] [Info] Start training from score -0.043536\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 4180, number of negative: 4366\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000776 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 556\n",
      "[LightGBM] [Info] Number of data points in the train set: 8546, number of used features: 107\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.489118 -> initscore=-0.043536\n",
      "[LightGBM] [Info] Start training from score -0.043536\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 4179, number of negative: 4367\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000748 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 556\n",
      "[LightGBM] [Info] Number of data points in the train set: 8546, number of used features: 107\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.489001 -> initscore=-0.044004\n",
      "[LightGBM] [Info] Start training from score -0.044004\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 4179, number of negative: 4367\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000644 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 552\n",
      "[LightGBM] [Info] Number of data points in the train set: 8546, number of used features: 107\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.489001 -> initscore=-0.044004\n",
      "[LightGBM] [Info] Start training from score -0.044004\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 4179, number of negative: 4367\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001368 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 556\n",
      "[LightGBM] [Info] Number of data points in the train set: 8546, number of used features: 107\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.489001 -> initscore=-0.044004\n",
      "[LightGBM] [Info] Start training from score -0.044004\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 4179, number of negative: 4367\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000792 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 557\n",
      "[LightGBM] [Info] Number of data points in the train set: 8546, number of used features: 107\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.489001 -> initscore=-0.044004\n",
      "[LightGBM] [Info] Start training from score -0.044004\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 4180, number of negative: 4367\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000456 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 555\n",
      "[LightGBM] [Info] Number of data points in the train set: 8547, number of used features: 107\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.489060 -> initscore=-0.043765\n",
      "[LightGBM] [Info] Start training from score -0.043765\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 4180, number of negative: 4367\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000778 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 554\n",
      "[LightGBM] [Info] Number of data points in the train set: 8547, number of used features: 107\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.489060 -> initscore=-0.043765\n",
      "[LightGBM] [Info] Start training from score -0.043765\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 4180, number of negative: 4367\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000626 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 558\n",
      "[LightGBM] [Info] Number of data points in the train set: 8547, number of used features: 107\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.489060 -> initscore=-0.043765\n",
      "[LightGBM] [Info] Start training from score -0.043765\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 4180, number of negative: 4367\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000588 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 555\n",
      "[LightGBM] [Info] Number of data points in the train set: 8547, number of used features: 107\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.489060 -> initscore=-0.043765\n",
      "[LightGBM] [Info] Start training from score -0.043765\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.62631579, 0.59473684, 0.61157895, 0.61789474, 0.59684211,\n",
       "       0.63368421, 0.60168599, 0.61854584, 0.62486828, 0.63540569])"
      ]
     },
     "execution_count": 529,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#10 fold CV on test data \n",
    "scores_test = cross_val_score (lgbm, X_test, y_test, cv = 10)\n",
    "scores_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "id": "29611fe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6161558427153236\n"
     ]
    }
   ],
   "source": [
    "# the average of the 10 folds \n",
    "print(np.mean(scores_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "id": "81d2125e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 18576, number of negative: 19406\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002164 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 563\n",
      "[LightGBM] [Info] Number of data points in the train set: 37982, number of used features: 107\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.489074 -> initscore=-0.043712\n",
      "[LightGBM] [Info] Start training from score -0.043712\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.6308251276920647, 0.6226832350463353)"
      ]
     },
     "execution_count": 531,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm = LGBMClassifier(n_estimators = 14, max_depth = 9, num_leaves = 31 ) \n",
    "lgbm.fit(X_train, y_train)\n",
    "lgbm_train_preds = lgbm.predict(X_train) \n",
    "lgbm_val_predicts = lgbm.predict(X_test)\n",
    "accuracy_score(lgbm_train_preds, y_train), accuracy_score(lgbm_val_predicts, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "id": "8035906a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6226832350463353"
      ]
     },
     "execution_count": 532,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm_test_preds = lgbm.predict(X_test)\n",
    "accuracy_score(lgbm_test_preds, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "id": "32e0bd26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 15922, number of negative: 16634\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002526 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 564\n",
      "[LightGBM] [Info] Number of data points in the train set: 32556, number of used features: 107\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.489065 -> initscore=-0.043747\n",
      "[LightGBM] [Info] Start training from score -0.043747\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 15922, number of negative: 16634\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001118 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 563\n",
      "[LightGBM] [Info] Number of data points in the train set: 32556, number of used features: 107\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.489065 -> initscore=-0.043747\n",
      "[LightGBM] [Info] Start training from score -0.043747\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 15922, number of negative: 16634\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002138 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 563\n",
      "[LightGBM] [Info] Number of data points in the train set: 32556, number of used features: 107\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.489065 -> initscore=-0.043747\n",
      "[LightGBM] [Info] Start training from score -0.043747\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 15922, number of negative: 16634\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002567 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 564\n",
      "[LightGBM] [Info] Number of data points in the train set: 32556, number of used features: 107\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.489065 -> initscore=-0.043747\n",
      "[LightGBM] [Info] Start training from score -0.043747\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 15922, number of negative: 16634\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002290 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 562\n",
      "[LightGBM] [Info] Number of data points in the train set: 32556, number of used features: 107\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.489065 -> initscore=-0.043747\n",
      "[LightGBM] [Info] Start training from score -0.043747\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 15923, number of negative: 16633\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003261 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 562\n",
      "[LightGBM] [Info] Number of data points in the train set: 32556, number of used features: 107\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.489096 -> initscore=-0.043624\n",
      "[LightGBM] [Info] Start training from score -0.043624\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 15923, number of negative: 16633\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001590 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 563\n",
      "[LightGBM] [Info] Number of data points in the train set: 32556, number of used features: 107\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.489096 -> initscore=-0.043624\n",
      "[LightGBM] [Info] Start training from score -0.043624\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    }
   ],
   "source": [
    "score1 = cross_val_score(lgbm, X_train, y_train, cv = 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "id": "a87bc39e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6198725712179453\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(score1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1261e7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3fce052",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bfead36",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
